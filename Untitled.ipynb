{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ai.analyzer.weighted_win_likelihood_analyzer import WeightedWinLikelihoodAnalyzer, WeightedState\n",
    "from ai.analyzer.nn_trainer import NNTrainer\n",
    "from ai.games.random_ai_game import RandomAIGame\n",
    "from ai.games.ai_game import AIGame\n",
    "from ai.players.random_ai_player import RandomAIPlayer\n",
    "from ai.players.nn_player import NNPlayer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winner is 1\n",
      "Weight values: count = 102, mean = 0.5, std = 0.1119758212150068, 25% = 0.49999999999998795, 75% = 0.500000000000012\n",
      "winner is 2\n",
      "Weight values: count = 100, mean = 0.5, std = 0.12434659813812447, 25% = 0.4999999999972228, 75% = 0.5000000000027772\n",
      "winner is 1\n",
      "Weight values: count = 94, mean = 0.5, std = 0.16493856491379344, 25% = 0.49999999999967804, 75% = 0.500000000000322\n",
      "winner is None\n",
      "winner is 1\n",
      "Weight values: count = 118, mean = 0.5, std = 0.09349525056091797, 25% = 0.5, 75% = 0.5\n",
      "winner is 2\n",
      "Weight values: count = 104, mean = 0.5000000000000001, std = 0.10405672784229836, 25% = 0.49999999999997646, 75% = 0.5000000000000235\n",
      "winner is 1\n",
      "Weight values: count = 86, mean = 0.5, std = 0.11453338754785897, 25% = 0.4999999996764103, 75% = 0.5000000003235897\n",
      "winner is 1\n",
      "Weight values: count = 164, mean = 0.5, std = 0.08296049370540347, 25% = 0.5, 75% = 0.5\n",
      "winner is 1\n",
      "Weight values: count = 78, mean = 0.4999999999999999, std = 0.12700127226631808, 25% = 0.4999999480908136, 75% = 0.5000000519091865\n",
      "winner is 1\n",
      "Weight values: count = 100, mean = 0.5, std = 0.1433987085168734, 25% = 0.4999999999989062, 75% = 0.5000000000010938\n",
      "winner is 2\n",
      "Weight values: count = 90, mean = 0.5, std = 0.08542302433094713, 25% = 0.4999999999630844, 75% = 0.5000000000369156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 13:34:15.195014 20252 deprecation_wrapper.py:119] From C:\\Users\\jkruger\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0819 13:34:15.231016 20252 deprecation_wrapper.py:119] From C:\\Users\\jkruger\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0819 13:34:15.236018 20252 deprecation_wrapper.py:119] From C:\\Users\\jkruger\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0819 13:34:15.264015 20252 deprecation_wrapper.py:119] From C:\\Users\\jkruger\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0819 13:34:15.305018 20252 deprecation_wrapper.py:119] From C:\\Users\\jkruger\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0819 13:34:15.330017 20252 deprecation_wrapper.py:119] From C:\\Users\\jkruger\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0819 13:34:15.388018 20252 deprecation_wrapper.py:119] From C:\\Users\\jkruger\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 828 samples, validate on 208 samples\n",
      "Epoch 1/200\n",
      "828/828 [==============================] - 0s 581us/step - loss: 0.1215 - acc: 0.0217 - val_loss: 0.0784 - val_acc: 0.0288\n",
      "Epoch 2/200\n",
      "828/828 [==============================] - 0s 227us/step - loss: 0.0698 - acc: 0.0229 - val_loss: 0.0646 - val_acc: 0.0240\n",
      "Epoch 3/200\n",
      "828/828 [==============================] - 0s 240us/step - loss: 0.0583 - acc: 0.0229 - val_loss: 0.0632 - val_acc: 0.0288\n",
      "Epoch 4/200\n",
      "828/828 [==============================] - 0s 238us/step - loss: 0.0525 - acc: 0.0242 - val_loss: 0.0512 - val_acc: 0.0288\n",
      "Epoch 5/200\n",
      "828/828 [==============================] - 0s 233us/step - loss: 0.0482 - acc: 0.0242 - val_loss: 0.0455 - val_acc: 0.0192\n",
      "Epoch 6/200\n",
      "828/828 [==============================] - 0s 239us/step - loss: 0.0470 - acc: 0.0254 - val_loss: 0.0457 - val_acc: 0.0192\n",
      "Epoch 7/200\n",
      "828/828 [==============================] - 0s 240us/step - loss: 0.0456 - acc: 0.0229 - val_loss: 0.0519 - val_acc: 0.0288\n",
      "Epoch 8/200\n",
      "828/828 [==============================] - 0s 264us/step - loss: 0.0424 - acc: 0.0242 - val_loss: 0.0408 - val_acc: 0.0240\n",
      "Epoch 9/200\n",
      "828/828 [==============================] - 0s 232us/step - loss: 0.0409 - acc: 0.0242 - val_loss: 0.0412 - val_acc: 0.0192\n",
      "Epoch 10/200\n",
      "828/828 [==============================] - 0s 239us/step - loss: 0.0404 - acc: 0.0254 - val_loss: 0.0395 - val_acc: 0.0192\n",
      "Epoch 11/200\n",
      "828/828 [==============================] - 0s 245us/step - loss: 0.0400 - acc: 0.0242 - val_loss: 0.0392 - val_acc: 0.0192\n",
      "Epoch 12/200\n",
      "828/828 [==============================] - 0s 254us/step - loss: 0.0399 - acc: 0.0229 - val_loss: 0.0383 - val_acc: 0.0048\n",
      "Epoch 13/200\n",
      "828/828 [==============================] - 0s 249us/step - loss: 0.0393 - acc: 0.0266 - val_loss: 0.0376 - val_acc: 0.0240\n",
      "Epoch 14/200\n",
      "828/828 [==============================] - 0s 250us/step - loss: 0.0393 - acc: 0.0254 - val_loss: 0.0371 - val_acc: 0.0144\n",
      "Epoch 15/200\n",
      "828/828 [==============================] - 0s 228us/step - loss: 0.0386 - acc: 0.0217 - val_loss: 0.0370 - val_acc: 0.0192\n",
      "Epoch 16/200\n",
      "828/828 [==============================] - 0s 243us/step - loss: 0.0387 - acc: 0.0266 - val_loss: 0.0384 - val_acc: 0.0096\n",
      "Epoch 17/200\n",
      "828/828 [==============================] - 0s 231us/step - loss: 0.0377 - acc: 0.0254 - val_loss: 0.0372 - val_acc: 0.0096\n",
      "Epoch 18/200\n",
      "828/828 [==============================] - 0s 245us/step - loss: 0.0370 - acc: 0.0242 - val_loss: 0.0354 - val_acc: 0.0096\n",
      "Epoch 19/200\n",
      "828/828 [==============================] - 0s 233us/step - loss: 0.0367 - acc: 0.0254 - val_loss: 0.0368 - val_acc: 0.0192\n",
      "Epoch 20/200\n",
      "828/828 [==============================] - 0s 257us/step - loss: 0.0368 - acc: 0.0266 - val_loss: 0.0361 - val_acc: 0.0144\n",
      "Epoch 21/200\n",
      "828/828 [==============================] - 0s 261us/step - loss: 0.0370 - acc: 0.0266 - val_loss: 0.0367 - val_acc: 0.0096\n",
      "Epoch 22/200\n",
      "828/828 [==============================] - 0s 255us/step - loss: 0.0370 - acc: 0.0266 - val_loss: 0.0387 - val_acc: 0.0192\n",
      "Epoch 23/200\n",
      "828/828 [==============================] - 0s 258us/step - loss: 0.0363 - acc: 0.0266 - val_loss: 0.0345 - val_acc: 0.0144\n",
      "Epoch 24/200\n",
      "828/828 [==============================] - 0s 296us/step - loss: 0.0363 - acc: 0.0254 - val_loss: 0.0346 - val_acc: 0.0096\n",
      "Epoch 25/200\n",
      "828/828 [==============================] - 0s 284us/step - loss: 0.0368 - acc: 0.0217 - val_loss: 0.0356 - val_acc: 0.0192\n",
      "Epoch 26/200\n",
      "828/828 [==============================] - 0s 269us/step - loss: 0.0360 - acc: 0.0217 - val_loss: 0.0338 - val_acc: 0.0096\n",
      "Epoch 27/200\n",
      "828/828 [==============================] - 0s 308us/step - loss: 0.0364 - acc: 0.0266 - val_loss: 0.0346 - val_acc: 0.0192\n",
      "Epoch 28/200\n",
      "828/828 [==============================] - 0s 264us/step - loss: 0.0362 - acc: 0.0302 - val_loss: 0.0342 - val_acc: 0.0096\n",
      "Epoch 29/200\n",
      "828/828 [==============================] - 0s 227us/step - loss: 0.0357 - acc: 0.0302 - val_loss: 0.0377 - val_acc: 0.0048\n",
      "Epoch 30/200\n",
      "828/828 [==============================] - 0s 266us/step - loss: 0.0362 - acc: 0.0229 - val_loss: 0.0368 - val_acc: 0.0192\n",
      "Epoch 31/200\n",
      "828/828 [==============================] - 0s 249us/step - loss: 0.0359 - acc: 0.0266 - val_loss: 0.0393 - val_acc: 0.0048\n",
      "Epoch 32/200\n",
      "828/828 [==============================] - 0s 248us/step - loss: 0.0370 - acc: 0.0254 - val_loss: 0.0371 - val_acc: 0.0048\n",
      "Epoch 33/200\n",
      "828/828 [==============================] - 0s 246us/step - loss: 0.0363 - acc: 0.0217 - val_loss: 0.0337 - val_acc: 0.0048\n",
      "Epoch 34/200\n",
      "828/828 [==============================] - 0s 260us/step - loss: 0.0361 - acc: 0.0290 - val_loss: 0.0354 - val_acc: 0.0048\n",
      "Epoch 35/200\n",
      "828/828 [==============================] - 0s 254us/step - loss: 0.0359 - acc: 0.0242 - val_loss: 0.0345 - val_acc: 0.0048\n",
      "Epoch 36/200\n",
      "828/828 [==============================] - 0s 284us/step - loss: 0.0348 - acc: 0.0254 - val_loss: 0.0331 - val_acc: 0.0096\n",
      "Epoch 37/200\n",
      "828/828 [==============================] - 0s 290us/step - loss: 0.0346 - acc: 0.0302 - val_loss: 0.0330 - val_acc: 0.0096\n",
      "Epoch 38/200\n",
      "828/828 [==============================] - 0s 280us/step - loss: 0.0350 - acc: 0.0254 - val_loss: 0.0345 - val_acc: 0.0048\n",
      "Epoch 39/200\n",
      "828/828 [==============================] - 0s 290us/step - loss: 0.0349 - acc: 0.0278 - val_loss: 0.0345 - val_acc: 0.0048\n",
      "Epoch 40/200\n",
      "828/828 [==============================] - 0s 284us/step - loss: 0.0362 - acc: 0.0229 - val_loss: 0.0340 - val_acc: 0.0192\n",
      "Epoch 41/200\n",
      "828/828 [==============================] - 0s 303us/step - loss: 0.0349 - acc: 0.0217 - val_loss: 0.0341 - val_acc: 0.0048\n",
      "Epoch 42/200\n",
      "828/828 [==============================] - 0s 300us/step - loss: 0.0347 - acc: 0.0314 - val_loss: 0.0331 - val_acc: 0.0096\n",
      "Epoch 43/200\n",
      "828/828 [==============================] - 0s 262us/step - loss: 0.0344 - acc: 0.0242 - val_loss: 0.0331 - val_acc: 0.0048\n",
      "Epoch 44/200\n",
      "828/828 [==============================] - 0s 246us/step - loss: 0.0352 - acc: 0.0254 - val_loss: 0.0360 - val_acc: 0.0192\n",
      "Epoch 45/200\n",
      "828/828 [==============================] - 0s 251us/step - loss: 0.0348 - acc: 0.0254 - val_loss: 0.0325 - val_acc: 0.0048\n",
      "Epoch 46/200\n",
      "828/828 [==============================] - 0s 301us/step - loss: 0.0350 - acc: 0.0254 - val_loss: 0.0329 - val_acc: 0.0096\n",
      "Epoch 47/200\n",
      "828/828 [==============================] - 0s 290us/step - loss: 0.0354 - acc: 0.0242 - val_loss: 0.0374 - val_acc: 0.0048\n",
      "Epoch 48/200\n",
      "828/828 [==============================] - 0s 312us/step - loss: 0.0346 - acc: 0.0254 - val_loss: 0.0350 - val_acc: 0.0048\n",
      "Epoch 49/200\n",
      "828/828 [==============================] - 0s 268us/step - loss: 0.0347 - acc: 0.0266 - val_loss: 0.0331 - val_acc: 0.0048\n",
      "Epoch 50/200\n",
      "828/828 [==============================] - 0s 266us/step - loss: 0.0349 - acc: 0.0242 - val_loss: 0.0331 - val_acc: 0.0048\n",
      "Epoch 51/200\n",
      "828/828 [==============================] - 0s 263us/step - loss: 0.0347 - acc: 0.0278 - val_loss: 0.0326 - val_acc: 0.0144\n",
      "Epoch 52/200\n",
      "828/828 [==============================] - 0s 256us/step - loss: 0.0345 - acc: 0.0278 - val_loss: 0.0323 - val_acc: 0.0144\n",
      "Epoch 53/200\n",
      "828/828 [==============================] - 0s 256us/step - loss: 0.0343 - acc: 0.0278 - val_loss: 0.0329 - val_acc: 0.0144\n",
      "Epoch 54/200\n",
      "828/828 [==============================] - 0s 251us/step - loss: 0.0355 - acc: 0.0266 - val_loss: 0.0366 - val_acc: 0.0048\n",
      "Epoch 55/200\n",
      "828/828 [==============================] - 0s 279us/step - loss: 0.0346 - acc: 0.0314 - val_loss: 0.0325 - val_acc: 0.0096\n",
      "Epoch 56/200\n",
      "828/828 [==============================] - 0s 308us/step - loss: 0.0345 - acc: 0.0266 - val_loss: 0.0324 - val_acc: 0.0096\n",
      "Epoch 57/200\n",
      "828/828 [==============================] - 0s 302us/step - loss: 0.0340 - acc: 0.0266 - val_loss: 0.0321 - val_acc: 0.0144\n",
      "Epoch 58/200\n",
      "828/828 [==============================] - 0s 307us/step - loss: 0.0344 - acc: 0.0254 - val_loss: 0.0324 - val_acc: 0.0144\n",
      "Epoch 59/200\n",
      "828/828 [==============================] - 0s 302us/step - loss: 0.0355 - acc: 0.0254 - val_loss: 0.0366 - val_acc: 0.0048\n",
      "Epoch 60/200\n",
      "828/828 [==============================] - 0s 298us/step - loss: 0.0347 - acc: 0.0278 - val_loss: 0.0324 - val_acc: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "828/828 [==============================] - 0s 300us/step - loss: 0.0345 - acc: 0.0217 - val_loss: 0.0333 - val_acc: 0.0144\n",
      "Epoch 62/200\n",
      "828/828 [==============================] - 0s 273us/step - loss: 0.0343 - acc: 0.0302 - val_loss: 0.0322 - val_acc: 0.0096\n",
      "Epoch 63/200\n",
      "828/828 [==============================] - 0s 269us/step - loss: 0.0347 - acc: 0.0242 - val_loss: 0.0333 - val_acc: 0.0096\n",
      "Epoch 64/200\n",
      "828/828 [==============================] - 0s 269us/step - loss: 0.0344 - acc: 0.0290 - val_loss: 0.0317 - val_acc: 0.0096\n",
      "Epoch 65/200\n",
      "828/828 [==============================] - 0s 267us/step - loss: 0.0342 - acc: 0.0266 - val_loss: 0.0344 - val_acc: 0.0096\n",
      "Epoch 66/200\n",
      "828/828 [==============================] - 0s 320us/step - loss: 0.0343 - acc: 0.0254 - val_loss: 0.0331 - val_acc: 0.0144\n",
      "Epoch 67/200\n",
      "828/828 [==============================] - 0s 291us/step - loss: 0.0346 - acc: 0.0302 - val_loss: 0.0322 - val_acc: 0.0096\n",
      "Epoch 68/200\n",
      "828/828 [==============================] - 0s 307us/step - loss: 0.0337 - acc: 0.0266 - val_loss: 0.0319 - val_acc: 0.0048\n",
      "Epoch 69/200\n",
      "828/828 [==============================] - 0s 262us/step - loss: 0.0346 - acc: 0.0278 - val_loss: 0.0350 - val_acc: 0.0192\n",
      "Epoch 70/200\n",
      "828/828 [==============================] - 0s 263us/step - loss: 0.0346 - acc: 0.0266 - val_loss: 0.0325 - val_acc: 0.0144\n",
      "Epoch 71/200\n",
      "828/828 [==============================] - 0s 260us/step - loss: 0.0342 - acc: 0.0229 - val_loss: 0.0323 - val_acc: 0.0096\n",
      "Epoch 72/200\n",
      "828/828 [==============================] - 0s 256us/step - loss: 0.0344 - acc: 0.0278 - val_loss: 0.0321 - val_acc: 0.0144\n",
      "Epoch 73/200\n",
      "828/828 [==============================] - 0s 272us/step - loss: 0.0348 - acc: 0.0278 - val_loss: 0.0319 - val_acc: 0.0048\n",
      "Epoch 74/200\n",
      "828/828 [==============================] - 0s 266us/step - loss: 0.0345 - acc: 0.0278 - val_loss: 0.0322 - val_acc: 0.0048\n",
      "Epoch 75/200\n",
      "828/828 [==============================] - 0s 286us/step - loss: 0.0341 - acc: 0.0254 - val_loss: 0.0330 - val_acc: 0.0144\n",
      "Epoch 76/200\n",
      "828/828 [==============================] - 0s 233us/step - loss: 0.0345 - acc: 0.0266 - val_loss: 0.0372 - val_acc: 0.0048\n",
      "Epoch 77/200\n",
      "828/828 [==============================] - 0s 234us/step - loss: 0.0347 - acc: 0.0242 - val_loss: 0.0320 - val_acc: 0.0048\n",
      "Epoch 78/200\n",
      "828/828 [==============================] - 0s 236us/step - loss: 0.0342 - acc: 0.0266 - val_loss: 0.0321 - val_acc: 0.0096\n",
      "Epoch 79/200\n",
      "828/828 [==============================] - 0s 242us/step - loss: 0.0354 - acc: 0.0229 - val_loss: 0.0327 - val_acc: 0.0096\n",
      "Epoch 80/200\n",
      "828/828 [==============================] - 0s 231us/step - loss: 0.0341 - acc: 0.0266 - val_loss: 0.0323 - val_acc: 0.0048\n",
      "Epoch 81/200\n",
      "828/828 [==============================] - 0s 239us/step - loss: 0.0344 - acc: 0.0314 - val_loss: 0.0314 - val_acc: 0.0144\n",
      "Epoch 82/200\n",
      "828/828 [==============================] - 0s 239us/step - loss: 0.0335 - acc: 0.0278 - val_loss: 0.0317 - val_acc: 0.0144\n",
      "Epoch 83/200\n",
      "828/828 [==============================] - 0s 245us/step - loss: 0.0339 - acc: 0.0254 - val_loss: 0.0337 - val_acc: 0.0096\n",
      "Epoch 84/200\n",
      "828/828 [==============================] - 0s 242us/step - loss: 0.0341 - acc: 0.0278 - val_loss: 0.0314 - val_acc: 0.0144\n",
      "Epoch 85/200\n",
      "828/828 [==============================] - 0s 239us/step - loss: 0.0352 - acc: 0.0266 - val_loss: 0.0325 - val_acc: 0.0144\n",
      "Epoch 86/200\n",
      "828/828 [==============================] - 0s 244us/step - loss: 0.0337 - acc: 0.0302 - val_loss: 0.0352 - val_acc: 0.0048\n",
      "Epoch 87/200\n",
      "828/828 [==============================] - 0s 256us/step - loss: 0.0338 - acc: 0.0278 - val_loss: 0.0319 - val_acc: 0.0144\n",
      "Epoch 88/200\n",
      "828/828 [==============================] - 0s 238us/step - loss: 0.0337 - acc: 0.0266 - val_loss: 0.0316 - val_acc: 0.0096\n",
      "Epoch 89/200\n",
      "828/828 [==============================] - 0s 234us/step - loss: 0.0337 - acc: 0.0242 - val_loss: 0.0345 - val_acc: 0.0144\n",
      "Epoch 90/200\n",
      "828/828 [==============================] - 0s 232us/step - loss: 0.0340 - acc: 0.0254 - val_loss: 0.0314 - val_acc: 0.0144\n",
      "Epoch 91/200\n",
      "828/828 [==============================] - 0s 243us/step - loss: 0.0338 - acc: 0.0278 - val_loss: 0.0313 - val_acc: 0.0096\n",
      "Epoch 92/200\n",
      "828/828 [==============================] - 0s 231us/step - loss: 0.0335 - acc: 0.0302 - val_loss: 0.0312 - val_acc: 0.0096\n",
      "Epoch 93/200\n",
      "828/828 [==============================] - 0s 250us/step - loss: 0.0337 - acc: 0.0278 - val_loss: 0.0319 - val_acc: 0.0048\n",
      "Epoch 94/200\n",
      "828/828 [==============================] - 0s 240us/step - loss: 0.0339 - acc: 0.0266 - val_loss: 0.0325 - val_acc: 0.0048\n",
      "Epoch 95/200\n",
      "828/828 [==============================] - 0s 273us/step - loss: 0.0336 - acc: 0.0254 - val_loss: 0.0311 - val_acc: 0.0048\n",
      "Epoch 96/200\n",
      "828/828 [==============================] - 0s 266us/step - loss: 0.0335 - acc: 0.0242 - val_loss: 0.0313 - val_acc: 0.0144\n",
      "Epoch 97/200\n",
      "828/828 [==============================] - 0s 280us/step - loss: 0.0335 - acc: 0.0254 - val_loss: 0.0312 - val_acc: 0.0096\n",
      "Epoch 98/200\n",
      "828/828 [==============================] - 0s 238us/step - loss: 0.0341 - acc: 0.0314 - val_loss: 0.0331 - val_acc: 0.0144\n",
      "Epoch 99/200\n",
      "828/828 [==============================] - 0s 238us/step - loss: 0.0336 - acc: 0.0242 - val_loss: 0.0344 - val_acc: 0.0144\n",
      "Epoch 100/200\n",
      "828/828 [==============================] - 0s 234us/step - loss: 0.0336 - acc: 0.0254 - val_loss: 0.0324 - val_acc: 0.0144\n",
      "Epoch 101/200\n",
      "828/828 [==============================] - 0s 246us/step - loss: 0.0339 - acc: 0.0290 - val_loss: 0.0312 - val_acc: 0.0048\n",
      "Epoch 102/200\n",
      "828/828 [==============================] - 0s 232us/step - loss: 0.0334 - acc: 0.0326 - val_loss: 0.0320 - val_acc: 0.0048\n",
      "Epoch 103/200\n",
      "828/828 [==============================] - 0s 244us/step - loss: 0.0332 - acc: 0.0278 - val_loss: 0.0309 - val_acc: 0.0144\n",
      "Epoch 104/200\n",
      "828/828 [==============================] - 0s 246us/step - loss: 0.0336 - acc: 0.0254 - val_loss: 0.0311 - val_acc: 0.0096\n",
      "Epoch 105/200\n",
      "828/828 [==============================] - 0s 232us/step - loss: 0.0339 - acc: 0.0314 - val_loss: 0.0313 - val_acc: 0.0096\n",
      "Epoch 106/200\n",
      "828/828 [==============================] - 0s 233us/step - loss: 0.0345 - acc: 0.0302 - val_loss: 0.0339 - val_acc: 0.0048\n",
      "Epoch 107/200\n",
      "828/828 [==============================] - 0s 248us/step - loss: 0.0336 - acc: 0.0217 - val_loss: 0.0308 - val_acc: 0.0048\n",
      "Epoch 108/200\n",
      "828/828 [==============================] - 0s 237us/step - loss: 0.0333 - acc: 0.0242 - val_loss: 0.0318 - val_acc: 0.0048\n",
      "Epoch 109/200\n",
      "828/828 [==============================] - 0s 250us/step - loss: 0.0340 - acc: 0.0229 - val_loss: 0.0309 - val_acc: 0.0144\n",
      "Epoch 110/200\n",
      "828/828 [==============================] - 0s 261us/step - loss: 0.0332 - acc: 0.0217 - val_loss: 0.0307 - val_acc: 0.0096\n",
      "Epoch 111/200\n",
      "828/828 [==============================] - 0s 268us/step - loss: 0.0330 - acc: 0.0290 - val_loss: 0.0311 - val_acc: 0.0096\n",
      "Epoch 112/200\n",
      "828/828 [==============================] - 0s 298us/step - loss: 0.0333 - acc: 0.0302 - val_loss: 0.0306 - val_acc: 0.0096\n",
      "Epoch 113/200\n",
      "828/828 [==============================] - 0s 262us/step - loss: 0.0332 - acc: 0.0302 - val_loss: 0.0308 - val_acc: 0.0096\n",
      "Epoch 114/200\n",
      "828/828 [==============================] - 0s 262us/step - loss: 0.0335 - acc: 0.0278 - val_loss: 0.0307 - val_acc: 0.0048\n",
      "Epoch 115/200\n",
      "828/828 [==============================] - 0s 251us/step - loss: 0.0334 - acc: 0.0266 - val_loss: 0.0348 - val_acc: 0.0144\n",
      "Epoch 116/200\n",
      "828/828 [==============================] - 0s 238us/step - loss: 0.0339 - acc: 0.0266 - val_loss: 0.0319 - val_acc: 0.0144\n",
      "Epoch 117/200\n",
      "828/828 [==============================] - 0s 250us/step - loss: 0.0332 - acc: 0.0217 - val_loss: 0.0315 - val_acc: 0.0144\n",
      "Epoch 118/200\n",
      "828/828 [==============================] - 0s 246us/step - loss: 0.0332 - acc: 0.0254 - val_loss: 0.0307 - val_acc: 0.0048\n",
      "Epoch 119/200\n",
      "828/828 [==============================] - 0s 239us/step - loss: 0.0338 - acc: 0.0278 - val_loss: 0.0328 - val_acc: 0.0144\n",
      "Epoch 120/200\n",
      "828/828 [==============================] - 0s 275us/step - loss: 0.0336 - acc: 0.0229 - val_loss: 0.0306 - val_acc: 0.0144\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828/828 [==============================] - 0s 250us/step - loss: 0.0330 - acc: 0.0266 - val_loss: 0.0314 - val_acc: 0.0048\n",
      "Epoch 122/200\n",
      "828/828 [==============================] - 0s 231us/step - loss: 0.0336 - acc: 0.0242 - val_loss: 0.0312 - val_acc: 0.0048\n",
      "Epoch 123/200\n",
      "828/828 [==============================] - 0s 234us/step - loss: 0.0332 - acc: 0.0266 - val_loss: 0.0306 - val_acc: 0.0096\n",
      "Epoch 124/200\n",
      "828/828 [==============================] - 0s 238us/step - loss: 0.0333 - acc: 0.0217 - val_loss: 0.0318 - val_acc: 0.0048\n",
      "Epoch 125/200\n",
      "828/828 [==============================] - 0s 234us/step - loss: 0.0332 - acc: 0.0242 - val_loss: 0.0306 - val_acc: 0.0144\n",
      "Epoch 126/200\n",
      "828/828 [==============================] - 0s 239us/step - loss: 0.0332 - acc: 0.0290 - val_loss: 0.0312 - val_acc: 0.0048\n",
      "Epoch 127/200\n",
      "828/828 [==============================] - 0s 239us/step - loss: 0.0329 - acc: 0.0278 - val_loss: 0.0317 - val_acc: 0.0096\n",
      "Epoch 128/200\n",
      "828/828 [==============================] - 0s 242us/step - loss: 0.0332 - acc: 0.0254 - val_loss: 0.0306 - val_acc: 0.0048\n",
      "Epoch 129/200\n",
      "828/828 [==============================] - 0s 237us/step - loss: 0.0331 - acc: 0.0278 - val_loss: 0.0309 - val_acc: 0.0048\n",
      "Epoch 130/200\n",
      "828/828 [==============================] - 0s 242us/step - loss: 0.0338 - acc: 0.0229 - val_loss: 0.0307 - val_acc: 0.0096\n",
      "Epoch 131/200\n",
      "828/828 [==============================] - 0s 254us/step - loss: 0.0334 - acc: 0.0266 - val_loss: 0.0310 - val_acc: 0.0096\n",
      "Epoch 132/200\n",
      "828/828 [==============================] - 0s 250us/step - loss: 0.0339 - acc: 0.0254 - val_loss: 0.0305 - val_acc: 0.0144\n",
      "Epoch 133/200\n",
      "828/828 [==============================] - 0s 256us/step - loss: 0.0336 - acc: 0.0278 - val_loss: 0.0315 - val_acc: 0.0048\n",
      "Epoch 134/200\n",
      "828/828 [==============================] - 0s 245us/step - loss: 0.0333 - acc: 0.0278 - val_loss: 0.0303 - val_acc: 0.0096\n",
      "Epoch 135/200\n",
      "828/828 [==============================] - 0s 243us/step - loss: 0.0331 - acc: 0.0254 - val_loss: 0.0306 - val_acc: 0.0096\n",
      "Epoch 136/200\n",
      "828/828 [==============================] - 0s 248us/step - loss: 0.0330 - acc: 0.0254 - val_loss: 0.0304 - val_acc: 0.0096\n",
      "Epoch 137/200\n",
      "828/828 [==============================] - 0s 252us/step - loss: 0.0333 - acc: 0.0278 - val_loss: 0.0304 - val_acc: 0.0144\n",
      "Epoch 138/200\n",
      "828/828 [==============================] - 0s 240us/step - loss: 0.0327 - acc: 0.0278 - val_loss: 0.0308 - val_acc: 0.0048\n",
      "Epoch 139/200\n",
      "828/828 [==============================] - 0s 263us/step - loss: 0.0331 - acc: 0.0242 - val_loss: 0.0315 - val_acc: 0.0048\n",
      "Epoch 140/200\n",
      "828/828 [==============================] - 0s 263us/step - loss: 0.0328 - acc: 0.0278 - val_loss: 0.0303 - val_acc: 0.0096\n",
      "Epoch 141/200\n",
      "828/828 [==============================] - 0s 242us/step - loss: 0.0331 - acc: 0.0242 - val_loss: 0.0305 - val_acc: 0.0096\n",
      "Epoch 142/200\n",
      "828/828 [==============================] - 0s 244us/step - loss: 0.0331 - acc: 0.0217 - val_loss: 0.0312 - val_acc: 0.0144\n",
      "Epoch 143/200\n",
      "828/828 [==============================] - 0s 254us/step - loss: 0.0335 - acc: 0.0278 - val_loss: 0.0309 - val_acc: 0.0144\n",
      "Epoch 144/200\n",
      "828/828 [==============================] - 0s 252us/step - loss: 0.0331 - acc: 0.0290 - val_loss: 0.0313 - val_acc: 0.0096\n",
      "Epoch 145/200\n",
      "828/828 [==============================] - 0s 261us/step - loss: 0.0328 - acc: 0.0266 - val_loss: 0.0313 - val_acc: 0.0096\n",
      "Epoch 146/200\n",
      "828/828 [==============================] - 0s 309us/step - loss: 0.0332 - acc: 0.0278 - val_loss: 0.0309 - val_acc: 0.0048\n",
      "Epoch 147/200\n",
      "828/828 [==============================] - 0s 298us/step - loss: 0.0330 - acc: 0.0242 - val_loss: 0.0307 - val_acc: 0.0048\n",
      "Epoch 148/200\n",
      "828/828 [==============================] - 0s 304us/step - loss: 0.0328 - acc: 0.0242 - val_loss: 0.0305 - val_acc: 0.0144\n",
      "Epoch 149/200\n",
      "828/828 [==============================] - 0s 324us/step - loss: 0.0327 - acc: 0.0314 - val_loss: 0.0305 - val_acc: 0.0096\n",
      "Epoch 150/200\n",
      "828/828 [==============================] - 0s 426us/step - loss: 0.0332 - acc: 0.0266 - val_loss: 0.0304 - val_acc: 0.0096\n",
      "Epoch 151/200\n",
      "828/828 [==============================] - ETA: 0s - loss: 0.0338 - acc: 0.0261    - 0s 401us/step - loss: 0.0328 - acc: 0.0242 - val_loss: 0.0317 - val_acc: 0.0096\n",
      "Epoch 152/200\n",
      "828/828 [==============================] - 0s 406us/step - loss: 0.0330 - acc: 0.0278 - val_loss: 0.0309 - val_acc: 0.0096\n",
      "Epoch 153/200\n",
      "828/828 [==============================] - 0s 386us/step - loss: 0.0337 - acc: 0.0254 - val_loss: 0.0304 - val_acc: 0.0144\n",
      "Epoch 154/200\n",
      "828/828 [==============================] - 0s 367us/step - loss: 0.0330 - acc: 0.0242 - val_loss: 0.0302 - val_acc: 0.0048\n",
      "Epoch 155/200\n",
      "828/828 [==============================] - 0s 371us/step - loss: 0.0329 - acc: 0.0254 - val_loss: 0.0305 - val_acc: 0.0144\n",
      "Epoch 156/200\n",
      "828/828 [==============================] - 0s 319us/step - loss: 0.0327 - acc: 0.0217 - val_loss: 0.0313 - val_acc: 0.0144\n",
      "Epoch 157/200\n",
      "828/828 [==============================] - 0s 283us/step - loss: 0.0337 - acc: 0.0278 - val_loss: 0.0320 - val_acc: 0.0048\n",
      "Epoch 158/200\n",
      "828/828 [==============================] - 0s 364us/step - loss: 0.0330 - acc: 0.0205 - val_loss: 0.0303 - val_acc: 0.0144\n",
      "Epoch 159/200\n",
      "828/828 [==============================] - 0s 365us/step - loss: 0.0328 - acc: 0.0278 - val_loss: 0.0311 - val_acc: 0.0048\n",
      "Epoch 160/200\n",
      "828/828 [==============================] - 0s 370us/step - loss: 0.0329 - acc: 0.0229 - val_loss: 0.0304 - val_acc: 0.0096\n",
      "Epoch 161/200\n",
      "828/828 [==============================] - 0s 396us/step - loss: 0.0328 - acc: 0.0229 - val_loss: 0.0306 - val_acc: 0.0144\n",
      "Epoch 162/200\n",
      "828/828 [==============================] - 0s 441us/step - loss: 0.0335 - acc: 0.0302 - val_loss: 0.0303 - val_acc: 0.0096\n",
      "Epoch 163/200\n",
      "828/828 [==============================] - 0s 384us/step - loss: 0.0327 - acc: 0.0290 - val_loss: 0.0306 - val_acc: 0.0096\n",
      "Epoch 164/200\n",
      "828/828 [==============================] - 0s 335us/step - loss: 0.0329 - acc: 0.0217 - val_loss: 0.0304 - val_acc: 0.0144\n",
      "Epoch 165/200\n",
      "828/828 [==============================] - 0s 368us/step - loss: 0.0327 - acc: 0.0290 - val_loss: 0.0316 - val_acc: 0.0192\n",
      "Epoch 166/200\n",
      "828/828 [==============================] - 0s 380us/step - loss: 0.0328 - acc: 0.0254 - val_loss: 0.0311 - val_acc: 0.0192\n",
      "Epoch 167/200\n",
      "828/828 [==============================] - 0s 401us/step - loss: 0.0331 - acc: 0.0229 - val_loss: 0.0306 - val_acc: 0.0144\n",
      "Epoch 168/200\n",
      "828/828 [==============================] - 0s 335us/step - loss: 0.0329 - acc: 0.0290 - val_loss: 0.0307 - val_acc: 0.0144\n",
      "Epoch 169/200\n",
      "828/828 [==============================] - 0s 280us/step - loss: 0.0330 - acc: 0.0278 - val_loss: 0.0305 - val_acc: 0.0096\n",
      "Epoch 170/200\n",
      "828/828 [==============================] - 0s 319us/step - loss: 0.0328 - acc: 0.0266 - val_loss: 0.0309 - val_acc: 0.0144\n",
      "Epoch 171/200\n",
      "828/828 [==============================] - 0s 256us/step - loss: 0.0327 - acc: 0.0217 - val_loss: 0.0315 - val_acc: 0.0048\n",
      "Epoch 172/200\n",
      "828/828 [==============================] - 0s 287us/step - loss: 0.0330 - acc: 0.0254 - val_loss: 0.0308 - val_acc: 0.0048\n",
      "Epoch 173/200\n",
      "828/828 [==============================] - 0s 280us/step - loss: 0.0325 - acc: 0.0278 - val_loss: 0.0311 - val_acc: 0.0096\n",
      "Epoch 174/200\n",
      "828/828 [==============================] - 0s 277us/step - loss: 0.0329 - acc: 0.0254 - val_loss: 0.0307 - val_acc: 0.0144\n",
      "Epoch 175/200\n",
      "828/828 [==============================] - 0s 239us/step - loss: 0.0330 - acc: 0.0302 - val_loss: 0.0310 - val_acc: 0.0096\n",
      "Epoch 176/200\n",
      "828/828 [==============================] - 0s 238us/step - loss: 0.0327 - acc: 0.0266 - val_loss: 0.0312 - val_acc: 0.0144\n",
      "Epoch 177/200\n",
      "828/828 [==============================] - 0s 240us/step - loss: 0.0328 - acc: 0.0302 - val_loss: 0.0324 - val_acc: 0.0096\n",
      "Epoch 178/200\n",
      "828/828 [==============================] - 0s 248us/step - loss: 0.0328 - acc: 0.0229 - val_loss: 0.0311 - val_acc: 0.0048\n",
      "Epoch 179/200\n",
      "828/828 [==============================] - 0s 269us/step - loss: 0.0327 - acc: 0.0266 - val_loss: 0.0324 - val_acc: 0.0192\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828/828 [==============================] - 0s 261us/step - loss: 0.0331 - acc: 0.0302 - val_loss: 0.0320 - val_acc: 0.0192\n",
      "Epoch 181/200\n",
      "828/828 [==============================] - 0s 220us/step - loss: 0.0333 - acc: 0.0254 - val_loss: 0.0320 - val_acc: 0.0048\n",
      "Epoch 182/200\n",
      "828/828 [==============================] - 0s 267us/step - loss: 0.0335 - acc: 0.0229 - val_loss: 0.0331 - val_acc: 0.0192\n",
      "Epoch 183/200\n",
      "828/828 [==============================] - 0s 278us/step - loss: 0.0325 - acc: 0.0254 - val_loss: 0.0321 - val_acc: 0.0144\n",
      "Epoch 184/200\n",
      "828/828 [==============================] - 0s 322us/step - loss: 0.0326 - acc: 0.0266 - val_loss: 0.0324 - val_acc: 0.0144\n",
      "Epoch 185/200\n",
      "828/828 [==============================] - 0s 364us/step - loss: 0.0325 - acc: 0.0229 - val_loss: 0.0320 - val_acc: 0.0144\n",
      "Epoch 186/200\n",
      "828/828 [==============================] - 0s 447us/step - loss: 0.0327 - acc: 0.0266 - val_loss: 0.0321 - val_acc: 0.0144\n",
      "Epoch 187/200\n",
      "828/828 [==============================] - 0s 344us/step - loss: 0.0326 - acc: 0.0278 - val_loss: 0.0326 - val_acc: 0.0096\n",
      "Epoch 188/200\n",
      "828/828 [==============================] - 0s 383us/step - loss: 0.0323 - acc: 0.0266 - val_loss: 0.0326 - val_acc: 0.0096\n",
      "Epoch 189/200\n",
      "828/828 [==============================] - 0s 385us/step - loss: 0.0324 - acc: 0.0242 - val_loss: 0.0336 - val_acc: 0.0048\n",
      "Epoch 190/200\n",
      "828/828 [==============================] - 0s 516us/step - loss: 0.0325 - acc: 0.0314 - val_loss: 0.0359 - val_acc: 0.0048\n",
      "Epoch 191/200\n",
      "828/828 [==============================] - 0s 473us/step - loss: 0.0327 - acc: 0.0254 - val_loss: 0.0329 - val_acc: 0.0096\n",
      "Epoch 192/200\n",
      "828/828 [==============================] - 0s 388us/step - loss: 0.0327 - acc: 0.0278 - val_loss: 0.0338 - val_acc: 0.0192\n",
      "Epoch 193/200\n",
      "828/828 [==============================] - 0s 384us/step - loss: 0.0322 - acc: 0.0205 - val_loss: 0.0339 - val_acc: 0.0192\n",
      "Epoch 194/200\n",
      "828/828 [==============================] - 0s 400us/step - loss: 0.0321 - acc: 0.0266 - val_loss: 0.0341 - val_acc: 0.0096\n",
      "Epoch 195/200\n",
      "828/828 [==============================] - 0s 355us/step - loss: 0.0320 - acc: 0.0290 - val_loss: 0.0348 - val_acc: 0.0144\n",
      "Epoch 196/200\n",
      "828/828 [==============================] - 0s 452us/step - loss: 0.0319 - acc: 0.0302 - val_loss: 0.0376 - val_acc: 0.0192\n",
      "Epoch 197/200\n",
      "828/828 [==============================] - 0s 379us/step - loss: 0.0325 - acc: 0.0338 - val_loss: 0.0348 - val_acc: 0.0096\n",
      "Epoch 198/200\n",
      "828/828 [==============================] - 0s 324us/step - loss: 0.0321 - acc: 0.0242 - val_loss: 0.0351 - val_acc: 0.0096\n",
      "Epoch 199/200\n",
      "828/828 [==============================] - 0s 324us/step - loss: 0.0320 - acc: 0.0302 - val_loss: 0.0374 - val_acc: 0.0192\n",
      "Epoch 200/200\n",
      "828/828 [==============================] - 0s 315us/step - loss: 0.0319 - acc: 0.0314 - val_loss: 0.0339 - val_acc: 0.0048\n",
      "MAE: 0.03386369451373365\n"
     ]
    }
   ],
   "source": [
    "all_weights = []\n",
    "games_processed = 0\n",
    "while (games_processed < 10):\n",
    "    game = RandomAIGame()\n",
    "    moves, winner = game.play()\n",
    "    print(f'winner is {winner}')\n",
    "    if winner is not None:\n",
    "        weights = WeightedWinLikelihoodAnalyzer().analyze_game(moves)\n",
    "        all_weights.append(weights)\n",
    "        games_processed += 1\n",
    "          \n",
    "all_weights = [item for sublist in all_weights for item in sublist]\n",
    "history, y_test, predictions = NNTrainer().train(all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd4HNXZt+9Hq96tYluW3AvuNli2MR1MC8VgINTQQkJ48wEhpJGENJLwhsAbEkKAkEDoJpRgTO8lGGNsjDG4y0W2XGQ1q1p1z/fHmdGMVqvispLLc1/XXrs79dnZmfM7TzkzYoxBURRFUTojqrcNUBRFUfZ/VCwURVGULlGxUBRFUbpExUJRFEXpEhULRVEUpUtULBRFUZQuUbFQDnhEZIiIGBGJ7sayV4nIRz1hl6IcTKhYKD2KiGwUkUYRyQqZvtRp8If0jmW7Jzr7cJ9visipvu9XOTZc2FM2KEp3ULFQeoMNwCXuFxGZACT0njm9g4gkAVOAD3yTrwTKnfeetifQ0/tUDhxULJTe4HHgCt/3K4HH/AuISJqIPCYiJSJSKCK3ikiUMy8gIneJSKmIrAfODLPuQyKyTUS2iMjv9rYhFJE4EfmziGx1Xn8WkThnXpaIvCwiO0WkXET+67P1J44N1SKyWkRm+jY7E5hvjGlwlh0MHA9cC5wmIv1CbDjH8cCqRGSdiJzuTM8QkX85dlWIyFxneruQm+O1jHA+PyIi94vIqyJSC5woImeKyOfOPjaLyK9D1j9GRD52futmZx9TRaTY75GJyPkisnRvjrmyf6FiofQGnwCpIjLGacQvAp4IWeavQBowDNuAXgFc7cz7NnAWcDiQD1wQsu6jQDMwwlnmVOBbe2nzz4EjgcnAJGAacKsz7wdAEZAN9AN+BhgROQy4HphqjEkBTgM2+rZ5BvCK7/sVwGJjzPPASuAyd4aITMMK6o+AdOA437YeBxKBcUBf4O7d+F2XAr8HUoCPgFrHjnSsCP+PiJzr2DAIeA3732Q7x2KpMWYRUAac4tvuNxy7lIMFY4y+9NVjL2wDdzK2of1f4HTgLSAaMMAQIAA0AGN9630HeN/5/C5wnW/eqc660djGugFI8M2/BHjP+XwV8FEHtg1xtxNm3jrgDN/304CNzufbgBeBESHrjAB2OL83Jsw2C4GBvu9rgZuczz8FvvDN+ztwd5ht5ABBoE+Yee1+q/P7RjifHwEe6+L/+rO7X8emFzpY7ifAk87nDKAOyOnt801f++6lnoXSWzyO7dVeRUgICsgCYrGNqUshkOt8HgBsDpnnMhiIAbY5oZKd2Ia2717aOyCMPQOcz3cCBcCbIrJeRG4BMMYUADcBvwZ2iMjTIjIAWvM0VcaYzc73o4GhwNPONp8CJojIZOf7QKxghTIQKDfGVOzh7/IfR0Rkuoi854T/KoHrsP9HZzaA9QzPFpFk4ELgv8aYbXtok7IfomKh9ArGmEJsovsM4D8hs0uBJmzD7zII2OJ83oZtuPzzXDZjPYssY0y680o1xozbS5O3hrFnq/Nbqo0xPzDGDAPOBm52cxPGmKeMMcc46xrgDmf90BDUlYAAS0VkO7DQme7mdjYDw8PYtRnIEJH0MPNqseEpAESkf5hlQm87/RQwD+vxpAEPOHZ1ZgPGmC3AAmA2cDkagjroULFQepNrgJOMMbX+icaYFuAZ4PcikuIkfm/Gy2s8A9woInki0ge4xbfuNuBN4P9EJFVEokRkuIgcvxt2xYlIvO8VBcwBbhWRbKfs95euPSJyloiMEBEBqoAWoEVEDhORk5xEeD2wy5kHNh/wqrN+PLY3fi02D+C+bgAucxLHDwFXi8hM5zflisho5/e+BtwnIn1EJEZEjnP28QUwTkQmO/v4dTd+ewrWU6l38iSX+uY9CZwsIheKSLSIZPo8H7Ae4o+BCcAL3diXcgChYqH0GsaYdcaYxR3MvgHbM16PTbw+BTzszPsH8Aa2MVxCe8/kCmwYawVQATyHje13lxpsw+6+TgJ+BywGlgFfOvv9nbP8SOBtZ70FwH3GmPeBOOAPWE9pOzYU9jMRSQPGAB8765/r7OcxY8x294UViABwujHmU2yC/26gEltu63o6l2M9sVXYHMlNAMaYNdh8ytvYfEh3BiN+F7hNRKqxgviMO8MYswnrEf0AW967FJvsd3nBsemF0A6AcuAjxujDjxSlJxE74O4CY8xBN/BORNYB3zHGvN3btij7FvUsFKXn2cnulbceEIjI+dgcyLu9bYuy71HPQlGUvUZE3gfGApcbY97oZXOUCKBioSiKonSJhqEURVGULumxu2tGmqysLDNkyJDeNkNRFOWA4rPPPis1xmR3tdxBIxZDhgxh8eKOqjAVRVGUcIhIYddLaRhKURRF6QYqFoqiKEqXqFgoiqIoXXLQ5CwURTl4aWpqoqioiPr6+t425YAlPj6evLw8YmJi9mh9FQtFUfZ7ioqKSElJYciQIdj7NSq7gzGGsrIyioqKGDp06B5tQ8NQiqLs99TX15OZmalCsYeICJmZmXvlmalYKIpyQKBCsXfs7fE75MXi44JSLnxgAX96a01vm6IoirLfElGxEJHTRWS1iBS4j5oMmX+ciCwRkWYRucA3fbKILBCR5SKyTEQuipSNFXVNfLqxnIId1ZHahaIoBwHJycm9bUKvEjGxEJEA8Dfga9i7UV4iImNDFtuEfQbzUyHT64ArnEdhng78uYPHRu41gSjrmjW36A0VFUVROiKSnsU0oMAYs94Y04h9EP05/gWMMRuNMcuAYMj0NcaYtc7nrdinf3V575I9IdoRi5agioWiKLtHYWEhM2fOZOLEicycOZNNmzYB8OyzzzJ+/HgmTZrEccfZp9wuX76cadOmMXnyZCZOnMjatWt70/TdJpKls7nYB7y7FAHTd3cjznOAY4F1YeZdi31uMYMGDdojIwMBx7NQsVCUA4Iht7wSke1u/MOZu73O9ddfzxVXXMGVV17Jww8/zI033sjcuXO57bbbeOONN8jNzWXnzp0APPDAA3zve9/jsssuo7GxkZaWli62vn8RSc8iXOp9t1pkEckBHgeuNsYEQ+cbYx40xuQbY/Kzs/fM8VDPQlGUPWXBggVceumlAFx++eV89JF9zPnRRx/NVVddxT/+8Y9WUZgxYwa33347d9xxB4WFhSQkJPSa3XtCJD2LImCg73sesLW7K4tIKvAKcKsx5pN9bFsrrTmLYDstUhRlP2RPPICewi1PfeCBB1i4cCGvvPIKkydPZunSpVx66aVMnz6dV155hdNOO41//vOfnHTSSb1scfeJpGexCBgpIkNFJBa4GJjXnRWd5V8AHjPGPBtBGwmIehaKouwZRx11FE8//TQATz75JMcccwwA69atY/r06dx2221kZWWxefNm1q9fz7Bhw7jxxhuZNWsWy5Yt603Td5uIeRbGmGYRuR54AwgADxtjlovIbcBiY8w8EZmKFYU+wNki8hunAupC4DggU0SucjZ5lTFm6b62M1pzFoqidIO6ujry8vJav998883cc889fPOb3+TOO+8kOzubf/3rXwD86Ec/Yu3atRhjmDlzJpMmTeIPf/gDTzzxBDExMfTv359f/vKXvfVT9oiD5hnc+fn5Zk8efrR0807O/dt8JuWl8eL1x0TAMkVR9paVK1cyZsyY3jbjgCfccRSRz4wx+V2te8iP4I6OUs9CURSlKw55sQhoNZSiKEqXHPJioZ6FoihK1xzyYqGehaIoStcc8mIRHWUPgY6zUBRF6ZhDXiwcraBFbySoKIrSIYe8WLieRctBUkKsKErkeOGFFxARVq1a1dum9DiHvFhozkJRlO4yZ84cjjnmmNZR25Fgf73B4CEvFloNpShKd6ipqWH+/Pk89NBDbcTij3/8IxMmTGDSpEnccot9xltBQQEnn3wykyZN4ogjjmDdunW8//77nHXWWa3rXX/99TzyyCMADBkyhNtuu41jjjmGZ599ln/84x9MnTqVSZMmcf7551NXVwdAcXExs2fPZtKkSUyaNImPP/6YX/ziF/zlL39p3e7Pf/5z7rnnnn3++yN5I8EDAvcW5ZqzUJQDhF+nRWi7lZ3Onjt3LqeffjqjRo0iIyODJUuWUFxczNy5c1m4cCGJiYmUl5cDcNlll3HLLbcwe/Zs6uvrCQaDbN68udPtx8fHt961tqysjG9/+9sA3HrrrTz00EPccMMN3HjjjRx//PG88MILtLS0UFNTw4ABAzjvvPP43ve+RzAY5Omnn+bTTz/dBwekLYe8WKhnoShKd5gzZw433XQTABdffDFz5swhGAxy9dVXk5iYCEBGRgbV1dVs2bKF2bNnA1YEusNFF3lPj/7qq6+49dZb2blzJzU1NZx22mkAvPvuuzz22GMABAIB0tLSSEtLIzMzk88//5zi4mIOP/xwMjMz99nvdjnkxUJzFopygNGFBxAJysrKePfdd/nqq68QEVpaWhARzj///Nbbkrt0dL+96Ohogr4S/fr6+jbzk5KSWj9fddVVzJ07l0mTJvHII4/w/vvvd2rft771LR555BG2b9/ON7/5zd38dd1DcxY6zkJRlC547rnnuOKKKygsLGTjxo1s3ryZoUOHkpGRwcMPP9yaUygvLyc1NZW8vDzmzp0LQENDA3V1dQwePJgVK1bQ0NBAZWUl77zzTof7q66uJicnh6amJp588snW6TNnzuT+++8HbCK8qqoKgNmzZ/P666+zaNGiVi9kX3PIi4XjWBA0HfcIFEU5tJkzZ05rWMnl/PPPZ+vWrcyaNYv8/HwmT57MXXfdBcDjjz/OPffcw8SJEznqqKPYvn07AwcO5MILL2TixIlcdtllHH744R3u77e//S3Tp0/nlFNOYfTo0a3T//KXv/Dee+8xYcIEpkyZwvLlywGIjY3lxBNP5MILLyQQCETgCOgtygEY/rNXaQkaCn7/NaIDh7x+Ksp+h96ivHOCwSBHHHEEzz77LCNHjuxwOb1F+V4S0CS3oigHKCtWrGDEiBHMnDmzU6HYWw75BDfYiqhGNMmtKMqBx9ixY1m/fn3E96OeBepZKMqBwMESMu8t9vb4qVjgjbVQz0JR9k/i4+MpKytTwdhDjDGUlZV1e8xHODQMBQS0fFZR9mvy8vIoKiqipKSkt005YImPjycvL2+P11exQD0LRdnfiYmJYejQob1txiGNhqHQUdyKoihdoWKBioWiKEpXqFigNxNUFEXpChUL1LNQFEXpChULfOMs9JkWiqIoYVGxAKID6lkoiqJ0hooFOs5CURSlK1Qs0HEWiqIoXaFiAQRExUJRFKUzIioWInK6iKwWkQIRuSXM/ONEZImINIvIBSHzrhSRtc7rykjaqdVQiqIonRMxsRCRAPA34GvAWOASERkbstgm4CrgqZB1M4BfAdOBacCvRKRPpGx1E9w6zkJRFCU8kfQspgEFxpj1xphG4GngHP8CxpiNxphlQGhm+TTgLWNMuTGmAngLOD1ShqpnoSiK0jmRFItcYLPve5EzbZ+tKyLXishiEVm8N3ej1BHciqIonRNJsZAw07rbGndrXWPMg8aYfGNMfnZ29m4Z58fzLLR0VlEUJRyRFIsiYKDvex6wtQfW3W2iW8dZqGehKIoSjkiKxSJgpIgMFZFY4GJgXjfXfQM4VUT6OIntU51pEUFzFoqiKJ0TMbEwxjQD12Mb+ZXAM8aY5SJym4jMAhCRqSJSBHwd+LuILHfWLQd+ixWcRcBtzrSIoGKhKIrSORF9Up4x5lXg1ZBpv/R9XoQNMYVb92Hg4Uja5xLQBLeiKEqn6Ahu9HYfiqIoXaFigXoWiqIoXaFigc+zaNHSWUVRlHCoWOC/Rbl6FoqiKOFQsUAffqQoitIVKhb4SmeNioWiKEo4VCzwPc9Cn8GtKIoSFhULtBpKURSlK1Qs0HEWiqIoXaFiAQT04UeKoiidomKB37PQcRaKoijhULFAx1koiqJ0hYoFnmcRVLFQFEUJi4oFWg2lKIrSFSoW6PMsFEVRukLFAvUsFEVRukLFAh1noSiK0hUqFqhnoSiK0hUqFkC0Uzqr4ywURVHCo2KBz7PQGwkqiqKERcUC3zgLvUW5oihKWFQs0HtDKYqidIWKBb7nWahYKIqihEXFAi8MpTkLRVGU8KhYoCO4FUVRukLFAohuzVlo6ayiKEo4VCzwblGunoWiKEp4VCzw3e5DS2cVRVHComKBDspTFEXpChUL9EaCiqIoXRFRsRCR00VktYgUiMgtYebHici/nfkLRWSIMz1GRB4VkS9FZKWI/DSSdkapWCiKonRKxMRCRALA34CvAWOBS0RkbMhi1wAVxpgRwN3AHc70rwNxxpgJwBTgO66QRIJoveusoihKp0TSs5gGFBhj1htjGoGngXNCljkHeNT5/BwwU0QEMECSiEQDCUAjUBUpQ3WchaIoSudEUixygc2+70XOtLDLGGOagUogEysctcA2YBNwlzGmPHQHInKtiCwWkcUlJSV7bKh7i3IdZ6EoihKeSIqFhJkW2nXvaJlpQAswABgK/EBEhrVb0JgHjTH5xpj87OzsPTZUPQtFUZTOiaRYFAEDfd/zgK0dLeOEnNKAcuBS4HVjTJMxZgcwH8iPlKFaDaUoitI5kRSLRcBIERkqIrHAxcC8kGXmAVc6ny8A3jXGGGzo6SSxJAFHAqsiZajeolxRFKVzIiYWTg7ieuANYCXwjDFmuYjcJiKznMUeAjJFpAC4GXDLa/8GJANfYUXnX8aYZZGyVT0LRVGUzomO5MaNMa8Cr4ZM+6Xvcz22TDZ0vZpw0yNFlKhnoSiK0hk6ghv1LBRFUbqiS7EQkX4i8pCIvOZ8Hysi10TetJ7DXw1l9GaCiqIo7eiOZ/EINu8wwPm+BrgpUgb1BiKi5bOKoiid0B2xyDLGPAMEoTVx3RJRq3qBgN6mXFEUpUO6Ixa1IpKJM6BORI7EjrQ+qNC8haIoSsd0pxrqZux4iOEiMh/Ixo6JOKgI6M0EFUVROqRLsTDGLBGR44HDsLfnWG2MaYq4ZT1Mq2ehD0BSFEVpR5diISJXhEw6QkQwxjwWIZt6BfUsFEVROqY7Yaipvs/xwExgCXBQioXmLBRFUdrTnTDUDf7vIpIGPB4xi3oJvU25oihKx+zJCO46YOS+NqS3Uc9CURSlY7qTs3gJ7zkUUdhHpD4TSaN6Ay2dVRRF6Zju5Czu8n1uBgqNMUURsqfXUM9CURSlY7qTs/igJwzpbbQaSlEUpWM6FAsRqab9Y1DBjrUwxpjUiFnVC8QEbPqmsVkT3IqiKKF0KBbGmJSeNKS3SU2wh6Kq/qAbb6goirLXdPvhRyLSFzvOAgBjzKaIWNRLpCfEArCzTsVCURQllO48z2KWiKwFNgAfABuB1yJsV4+TmhADQOUuFQtFUZRQujPO4rfAkcAaY8xQ7Aju+RG1qhdIU7FQFEXpkO6IRZMxpgyIEpEoY8x7wOQI29XjpCeqWCiKonREd3IWO0UkGfgv8KSI7MCOtzioaPUsNGehKIrSjg49CxG5V0SOBs7B3uLjJuB1YB1wds+Y13O4YrFzV2MvW6IoirL/0ZlnsRY7ejsH+DcwxxjzaI9Y1Quka85CURSlQzr0LIwxfzHGzACOB8qBf4nIShH5hYiM6jELewi3GkpLZxVFUdrTZYLbGFNojLnDGHM4cClwHrAy4pb1MG4Yqko9C0VRlHZ0Z5xFjIicLSJPYsdXrAHOj7hlPYxWQymKonRMZ/eGOgW4BDgT+BR4GrjWGFPbQ7b1KMlx0QSihNrGFppagq33ilIURVE69yx+BiwAxhhjzjbGPHmwCgWAiOjAPEVRlA7o7EaCJ/akIfsDaQkxlNc2srOuiazkuN42R1EUZb9BYy0+9P5QiqIo4YmoWIjI6SKyWkQKROSWMPPjROTfzvyFIjLEN2+iiCwQkeUi8qWIxIeuv69J14ooRVGUsERMLEQkAPwN+Br2ud2XiMjYkMWuASqMMSOAu4E7nHWjgSeA64wx44ATgIi34DqKW1EUJTyR9CymAQXGmPXGmEZsNdU5IcucA7ijwp8DZoqIAKcCy4wxXwAYY8qMMS0RtBXQ+0MpiqJ0RCTFIhfY7Pte5EwLu4wxphmoBDKBUYARkTdEZImI/DiCdrbijrXYqWEoRVGUNnT7SXl7gISZFvpM746WiQaOAaZib2L4joh8Zox5p83KItcC1wIMGjRorw3W0llFUZTwRNKzKAIG+r7nAVs7WsbJU6Rh70NVBHxgjCk1xtQBrwJHhO7AGPOgMSbfGJOfnZ291wanahhKURQlLJEUi0XASBEZKiKxwMXAvJBl5gFXOp8vAN41xhjgDWCiiCQ6InI8sCKCtgJeNZSGoRRFUdoSsTCUMaZZRK7HNvwB4GFjzHIRuQ1YbIyZBzwEPC4iBViP4mJn3QoR+RNWcAzwqjHmlUjZ6tI31Vbnbq+sj/SuFEVRDigimbPAGPMqNoTkn/ZL3+d64OsdrPsEtny2xxickQjApvI6jDHYwixFURRFR3D7SE+MISUumpqGZio0b6EoitKKioUPEWGg410Ulh2090xUFEXZbVQsQhic6YWiFEVRFIuKRQiDHM9is4qFoihKKyoWIXhhKBULRVEUFxWLEDQMpSiK0h4VixA0DKUoitIeFYsQBqQnEIgStlXV09Ac8RvdKoqiHBCoWIQQE4hiQHo8xkBRxa7eNkdRFGW/QMUiDEMykwBYX6JjLRRFUUDFIiyH9UsBYNW2ql62RFEUZf9AxSIMo3NSAVi1vbqXLVEURdk/ULEIw+j+1rNYuV09C0VRFFCxCMvIfskEooSNpbXsatSKKEVRFBWLMMRFBxienUTQwJpiDUUpiqKoWHTAGCdvsVKT3IqiKCoWHTG6vya5FUVRXFQsOmB0jk1yzy8opbkl2MvWKIqi9C4qFh1w5NBMctMTWLujhr9/uL63zVEURelVVCw6ICE2wB3nTwTgz2+vYa0muhVFOYRRseiEY0Zmccm0QTS1GG5/dWVvm6MoitJrqFh0wQ9OHUVyXDTvrS7h44LS3jZHURSlV1Cx6IKs5DiuO34YAHe/vaaXrVEURekdVCy6wVVHDyUQJXxWWEFNQ3Nvm6MoitLjqFh0g+S4aMbnphE0sKSworfNURRF6XFULLrJ9KEZAHy6obyXLVEURel5VCy6ydQhKhaKohy6qFh0k6lD+gCwtGgn9U16J1pFUQ4tVCy6SXpiLKP7p9DYHGTp5p29bY6iKEqPomKxGxw7MguAhz7a0MuWKIqi9CwqFrvBt48dRkJMgLdWFLN4o+YuFEU5dIioWIjI6SKyWkQKROSWMPPjROTfzvyFIjIkZP4gEakRkR9G0s7u0jc1nm8fZwfo3fKfLynYofeLUhTl0CBiYiEiAeBvwNeAscAlIjI2ZLFrgApjzAjgbuCOkPl3A69FysY94drjhjE0K4mCHTWcec9H/OrFr1i8sZwd1fW9bZqiKErEiKRnMQ0oMMasN8Y0Ak8D54Qscw7wqPP5OWCmiAiAiJwLrAeWR9DG3SY5Lpp51x/N16fk0dAc5NEFhVzwwAKm/f4dfvfyCoJB09smKoqi7HOiI7jtXGCz73sRML2jZYwxzSJSCWSKyC7gJ8ApQIchKBG5FrgWYNCgQfvO8i5IiY/hzq9P4ppjh/Lox4Ws2FrJ8q1V/POjDby5opj4mCiuO3445x2R12M2KYqiRJJIioWEmRba7e5omd8AdxtjahxHIyzGmAeBBwHy8/N7vEs/un8q/3veBAA+LijlO098xqbyOgBufuYL5heUER0lXD5jMONz03raPEVRlH1GJMWiCBjo+54HbO1gmSIRiQbSgHKsB3KBiPwRSAeCIlJvjLk3gvbuFUeNyGL+LSexqayOBevK+P2rK3l+SREA76zawUs3HE1OWkIvW6koirJnRFIsFgEjRWQosAW4GLg0ZJl5wJXAAuAC4F1jjAGOdRcQkV8DNfuzULikxscwPjeN8blpjMtNZUlhBR+uKeXTjeVc+9hnPPnt6aTGx/S2mYqiKLtNxBLcxphm4HrgDWAl8IwxZrmI3CYis5zFHsLmKAqAm4F25bUHKkcNz+L6k0by98unMDAjgS+3VHLx3z9hY2ktAC1Bw6KN5Ty5sJC5n2+htKahzfpWM7tmW+UufeSroigRR7rbKO3v5Ofnm8WLF/e2GWEpqqjj8oc+ZYMjFAPS4qnc1URto3ePqazkOB795lT6psTz+1dW8OHaUm6fPYHTx/envqmF+JhAu+0WV9Vz2p8/pHJXEz8/YwzXHDOUznI8iqIooYjIZ8aY/C6XU7HoGUprGvj9Kyt5Y/l26hyRGJSRyLShGawprmZZUSUi4P87YgLCqH4pLN9axfDsJM6eNIBLpw3i34s2U1XfxPKtVXy8rqx1+cMHpXP6uP6MG5DGjOGZBKLaC8fC9WW8vGwbPzztMNISNCSmKIc6Khb7KfVNLWyvrCctIYb0xBhEhIbmFn7y3DLmLt1KdJRw3KhsBqTH88Qnm7rcXnpiDDfNHMldb65p8xS/U8f24++XT2njaVTWNTHzT+9TWtPIRfkDueOCiZ1ue+vOXRggN73zxLwxhk83lDOqXwp9kmLbza9rbGZJ4U6OHJZBdKBn7zBTXttIQIS0RBVGRQmHisUBSH1TC3HRUYgIxhieXVxEIEo4dVw/vthcyZ1vrOKLokoOH5TO5IHpLFxfzo9OO4wTR/elrrGZt1YUs2hjOS8u3Up1fTO/nz2ey6YPZuW2KhYXVvDJujJe+XJb6/6e+vZ0jhpub464eGM5jy4o5PhR2QzOTOSVZdt4/JNCYgLCo1dPY/qwTIwxlNU2kpYQQ4yv0X9q4SZ+9sKX5KYn8J/vHkW/1PjWeU0tQS558BMWF1Zw5sQc/nLR5B4TjOKqek7/84fExwR44/vHdVhc8OCH61i9vYbbzxtPXHT7cJ+iHMyoWByEBIOGwvI6BmckEhUmxOTy0hdbuWHO58QEhEl56Xy2qaI1vBUTEM6eNID/LNmCCOQP7sO0oRn8878baGgOht1eUmyASQPTWVdSQ3FVQ2t47KTRfZmQm8bNz3zR6tWM6JvM16fkcdq4/gwwtWQUAAAgAElEQVTJSuKO11dx//vrWrc1ITeNEw7LJn9IBiu3VTG/oJRpQzI4c2IOQzKTaDGGzwor+GR9GedMziUpNsAdr69mR3U9fVPiuf6kEWQkxfLoxxt5eP4G0hNiuHDqQL5x5GC2V9bznyVbWLGtipF9kyksq+PtlcUAXHPMUC6dPojoKGFwZlKrPa9+uY3vPrkEgN+eO57Ljxy8V//RnrCupIblW6s4c0JO2NChokQSFYtDnNteWsHD8+2t1KOjhNPG9aeqvokzJ+Qw+4hcfvqfL3l52TYafQJx6th+VNQ1UtvQwqSB6XzjyEE8+OF6XlzqDY9Jig20Scy7HD8qm83ldax3kvjRUcLonBS+2lJFlMDPzxzLPe+spXJXU4c2xwSEphbvfMxOiSM7OY4V26raLNMSNITeVSUlLpqaxmZCT+eEmAANzS0YbD4oLjqK5//nKAZnJvLysm3c/spKqh2h658az/s/OqFNMUFxVT0frikhLSGG6UMzW8NZLUHDmuJq0hJiGOAL0zW1BHnww/XUN7XwneOHkxwXTVNLkA2ltQzOTGzjuRhjmPfFVn7y/DLqm4JcffQQfnX2OIwxzC8oY0B6PMOykzs8Xu42tlXWk5MW3xpybGoJ0tAcJDlu31TGl9U0UNfYwsCMxH2yPWUvMQb2YSGLioXCjqp6Fm2sYOyAVIZmJbWbX9PQzLurdvDOymKGZydzw0kj2lVTBYOGJZsqaGgO0i81jmFZydQ3t7BoYwXvrdrBoo3liMDDV04lLibA619tY8G6Ml78YivGQGp8NLeeNZYL8wdSuauJhevLWLSxnMWFFaQnxHD6+P58uLaUxRvLKa5qIEpgcGYSCTGBVpEYlJHIb2aN45Uvt/HcZ0VERwlTh2Rww8wRNDQFeeCDdSzcUE5MQPh6/kCmD83gX/M3snTzTn57zjjWFNfw+CeFrQUEWclxNDS3UF1vReL0cf0pLK9j5bYqUuOjqWtsIUoEhDZiGogSTjysL1ECn6wvo6q+GRH7fPbh2ckkxUWzcEM5XzgPx3KP14ptVVTuamJoVhK/PGss43JTmbNwM88s3syWnbsAWm27csZgGlsMcz7dRGJsgIeunMqM4Zm0BA1bKnbRPy2eooo65q8rIy0hhuc+K+LDNSUcPyqbv1w8mYq6Jq59bDHrS2s5angm1584gtw+Cdzx+mom5qZx1dFDqK5vJjE2ELbCDqBgRw03zPmclmCQGcMymbNoM43NQcbnpjL78DzOnpRD3xQv1LizzoYmO6rEq29q4dnFm+mXGs8pY/vtVsVeU0uQP7y2ivUlNdx+3oQ2A1uf+6yIt1cU8+PTDwsrqp9vqiAtIaZLwd2XNLcEWbC+jM837eSSaYPITonbtztY9gy8cB1c9TIMPmqfbFLFQulV3DzJrEkDul11tavR5myiooTahmaufXwxG0pqeeya6Yzoay/40poGEmICJPl6zcYYlhVVkpUS15qMbwkadlTXk5OWQFNLkI8KShk/II1rH1/M55tsYz5tSAYXTh3IOZMH8NHaUq5+ZFE7m2Kjozh2RBbVDc18VlhBi8+lyU1PoKSmoY2gAOSkxZOVHMeXWypbp6XERbd6MH76p8bz/04cTmpCDN97emm7+XHRURw3KptV26vYXL6rnfcVaisGGls8e6LE3svM9ehczzBKIK9PIrHRUYzNSWViXhrPLi6iclcTVfVNrRV7LomxgdZpUQJHj8hi7IBUVm6r5sM1JUwbmsF3TxjOe6t2kNsngfED0nhn1Q4q6hpZtLGczeVWFMfnpnL5kYPZVlnPx473NKp/CqP7pzCybwovLt3Ckws3cdLovswc05eHP9rIRwWlrcf1W8cOI69PAvVNLdz076UYY4/tTaeMYmJeGsVV9WQkxvL55p3c+cZq4mOi+Pvl+WQlxxITiGJk32Sq6pt5/attfLi2lCGZiQzOTKKuoZn+aQmM6JtETloCH64pobqhmVmTBlDX2MLC9WWU1jQwom8K04dmEDSGhuYgUSLEx0TxwZoSnv50MwvWl7Ue60l5aTxz3Yx9mwd74nwoeBtO+CmcsG+GpalYKAcFLUGzT+P4pTUNPPbxRo4ekcX0YZlt5m0orSUmIK29QWNsOM1NyO+orueNr7YTFx1gxvBMBmYkUlnXxMfrStlR3cCuphYSYgLMmjSA1IQYPiusoKklSL/UeAZlJPLec/dRvmEpv6ieTf6QDG44aSQzhmW25p+WbKrgiU8KWbejhl+ePZbnl2zhqYVeRVxagm30k2IDnDi6Lw3NQQakxXPeEXn85qXlLHFE8LRx/bj1zLHM+XQT93+wDmOsMG6vqmdTeR1JsQHqm4NthC+UMyfkMHNMX95bXcJF+QPJH9KHd1ft4D9LtvD+6h007+bdlUf1S2ZnXRM7qhu6XjiEzKRYBmYkhn2c8ci+yazdUdPtbaXER7d6lN1hQFo85XWN1Dd5ApwSH01tQ3NrKDQhJsCuJk9ch2UlUdvYTHFVAxPz0oiPDpCXkUBjc5DPN+2kX2ockwf24eSxfYmLjmJbZT1bd+5iSeFO1pXUEDSG6cMyuenkkW08OIyh5Q9DCDTspHzclWR8/Z5u/47OULFQlP0JY+CPQ2FXBeba95EBh3drtU1ldXy6sZys5FiOHZlNfVML0QFp11s1xlDX2EJDc5AMX/nywvVlrC6u5pJp9q7MxVX1DEhLoLElyJadu6hvauGNr7azYls1Z03MYcrgPjQ0BxmendRhuKi8tpH3V+9gW2U9ibEBjh2ZxW9eWsGyokoumJJHYVktG8vqOGl0X0b1SyEtIYYTD8umqcXw0hdbeWnZVlLio5k1KZeddY2s2l7NmmL7yk6J57rjh/HOyh1s2bmLKYP7cMWMwWQlxzHn001sKK1lTXE1Szbt5NzJA/jDeRN5adlW3l65g42lteSkxbc2vr85ZxyLNtgqv7w+CTQ0BympbiA2OorDB6ZzxoQctuzcRUl1A4mxAbbs3MW6khqKKnYxNieVppYga4qtEM0YlklenwQ+KihlW2U9IhAfHaAlaGhsCZKVHMs1xwzjzAk5DMpM5MuiSs5/4ON2XufuEBuIYmS/ZPL6JJCVHMeEhFIu/uRcAF5qOZLnh/2W4dnJDMpIZFBGIjOGZ3YYWuwMFQula+qrYMtiGHo8RO0DV7m2DCo2Qt6Uvd9WJChfD8EWyBoZ2f2UrIFgE/Qb500rLYB7neNy3j9g4oX288b50G8sJPSJrE09gDFm7+4gEO647YN9VdU3kRofQzBoKK6uJzs5rtPybdebbWoJ8tpX2xnZN5kxOamt80qqG8hIiiU2OgpjDDvrmkiOj25TTg7w1ZZK1pXUkJkUx8ayWgwwdUgfSqsb+W9BCR+sLiEuJkD/1DiOlBVkDJnEiGFDaGgOcv/763hrRXGb7Z0b9RF/jr0PgI+D47i08ecAzI76L9vJ4IFffH+PBtqqWChd8/pP4ZP74KInYcxZe7+9f18OK+fBtR/AgMl7v719STAIfxoDzbvg5lUQG6HKHmPgrpHQ3AA/WgfRTi//i6fhhe/Yz8f+AGb+ErYsgX+caIXiB2u8ZQ9F3OPWVA8/KoCY+K7XOVhwz4PRZ8HFT7ZOrqpvYm1xNcVVDWyp2MXIz27jhMoXAGjMHMPbJ7xAeVEBF356AbGmHr7zX8jpfKBtOLorFj07nFbZc4zxXvuK8vX2vWTVvtlekZMg3tIN0e7pTkrlJqjZDvWVsO2LyO2nphhqS6ChCqq9AZAU+Y5JyWr7vs1JaO+qgPl/6Xrb+/r/35/YVWGPW2M1lBX0tjU9i3s+FLd9KGhqfAxTBmdwxoQcvn3cME5IKmydF9tQwRnj+/ON0j9ZoRg3e4+EYndQsTgQCLbAw6fBb9Lh9lxY91731qsuhr/mw8d/DT+/ttRZblv4+btDfaW3Hffk74hgEP51Bjx1cfj5O1bBn8bBsmf33i4Xv01F7aueKN8Ad4+HhQ92vI36Krj/GHj5+x0vU+Fd0G2Oq19AS9fY98oib9qHf4Sd/gdLhvDZI/DbLHsOPD774BONKt+jbvZF56WlCf55Mjx9mb1+9pZdO+G+o+Cd30JjLTx4Irz+M2/+6tfg/0ZbL2F3qXZ+e2VRx7bu2gnbv6T1eXF1ZbDiRVj3rvVMv/bH3d/vbqJicSBQsho2L7Sfm2ph7VvdW2/du1C2FpbOCT+/zhGLqtBnUu2JjWt8n7sQi7pS2PQxrHnNXnihrHwJqopgyaPt5+2xfT6bwnk+K16Eys22h99RQ7zqFSj+Ej571OZnwrHTJxZVW+x70y7fhS5Qtg6aG9sKS0tjxx5PxUYbMgw6VTzr3m3XCz3g8Z+DpWs6Xq67VGy0nYJVL8Oif+799jYtgB3LYfHDUPgxbF0Cy/7tzV/ymO0crJi7+9t2f3uwqeNr8a1f2PlDjoHYZPt59Wt23ozrIbnv7u93N1GxOBAIbdyqOzihVr8G//2T19i5PbSytdASplywrty+7xOx8PUGuxKLmh3e552b4Kvn2wqau62tn++bXmGoTUWftZ/vehtVRR33DlfOs++mBVa/En4ZvwC4x3XbMtvQ9x0DfQbb9cvX2wYNINNJuNfuICwvfx+a6mDceTDlqra27A3GWHFc/freb6s7FK+AN34ODWGev1K9jz0L/zn99m/seVZTAm//uq3Qr3wZPrm/a0/NtWlXOXz5nP1cV2pzU8Z4Ycauzv2wtvo8UH9nw2XDh1aMArFw5v9BolPyvcU5j7MP2/197gEqFgcC7ol42Bn2vaPG/bUfwzu/8U5st4fW0tj+JGxusHH1zra3O5T6LhI3N9ARNb4qj9I18J/vwNzrvIbW3VZjzb7Lp/jtqypqe4GCd+EBrHyx/foN1VDwjvd9RQeN9c6Nvv04+3DFPncKZB3m2eP+JwOn2feaMGJRtdV6ErHJNtQwZlbn+98ddqyAt34Jz1y+Z43c7tBYB09fAgvuhYV/bz+/TRhqH3gW/u011cLyF2DRP+Cju+GjP9npxsC86+H1W2wBQmf4bfrqee9z9TYrRK7Q75FYbPE+V4QRCzefdewPrDC4YlG21r6n98z9zFQsDgTchsxtKEIbOrA98ErnpNux0r77T9yS1bYn6/bq6ny9q9oSGxbpLnXltuF0X8Ur2l8k4S74yi12XX+juO5d61KDDRkEW6B0rTe/aLENuTTVe9Maa2H9+97+t7Yf+dwGYzz7+o61724Dvv0re4H68wsrX2rf01z7JrQ0QPZokCi7/3CCWBEmDOWKfd5Urxe49XN73AOx0N9JTNa0LZUEvLxG1khIzoYhx0J8GpSsbHuc/Oyq6Dz/4eKeJy2NMO8Gm0sKBu3/Gfr7g0HYtNAe7/INbedt/dxOd49xY237Zd77vedJrZxnt7f9K28//gazrMDzhHessvmHcDTWevtsqrd2u7ieijgl4ZVbbKMO3v+xq8K+wApGOLEuW2f34+9sBH32VG1t6/nvLLRhx86oK/eKS9xt+NevKPSu0107Yf0H9pyb+i07LSmr7fb6qFgoAA01tgcYFQ2jTrPTqrfai81PzQ4b3gB7ATXVQ4Xvgl3xItw71d5XBtqKBcZ6A93lya/DE+d5r/uPsuMFwGv4Qj2C2lK4b4Zd3h9uWfOmz8Z59oJu9gnDh3fZ7T9zudewzLsBHjvH2/+Dx9vGuyOqt1svKqEPHPY1O23TJ/aYPHA0POqUDQ89DhKz7IW84YO221j5kn0/4goYdJRtMD5/knaES3C3ikW+JxarXrXvaQMhpb/9HNazcBrR1Fz7Hh3reZiLHw7/e5+4AP423YZdOsP/H21eCMv/A/+9C+6f0T72/vnj8PCpzv99tFccUfAOPHiCnX7fkbZxffn78NcpVgzAHv9P7rMNXnS8zc08fak99m5Ix98BCjbZc3fNm3DfdOsth+Ol78HfpjnhrZ9Zuws/drbnNMB5U53vW7xjuW2pFSC/t12/E179Udvtb/kM7s2Huf/TsbdTtbVtWNMEO6/maqyzifd7p9ntNzfaToPL2je9fQKsed0ej8FHeyKR6BOL+HTbeegBVCz2d7Z+bk/AfuMgMQMSMmz8201Ou/hjvqWroXydXc9l2b9tD7Jwvm10a0PWD+ethGPXTtuTioqGYSdCzmTAWFc/KtprjEtDPI2VL0FDpfUC/L1ev92bF9r4LHgXQKXTG1z7ppdQ3PypfR98NGSPcX7fMx3b7NqSdZi1GWD1q17owe1xDjwSpjti+tJN9sIG21N0RW3M2TDju/bzu7/z1gXbAFX5KpyqtloBqNxkw0jZo63Nfpv6DIbkfvZzWLFw/peUHG/atGttw7vwgfb5lZLV9v9pqu26RNjtlec6JfbLX4CljgC6ja6Le3xjEu22Vzti96VTsSYBe75t+ND+V6bFeo1gRckEIW+aJ3RrnOTsOie05zbuyf29dQqcQo4vng6fu9r6uX0vXg7FjjC550arWDi/rXqbdyyb6+3yrrDnTIaYJCuQK1/2tv/Fv63dK+bZkt64VFqrkVz8noV7znYWinrv9/baDDbBizfYogp8XtzWz+11usX5bW4nxY0qACT5blPTZ0jH+9rHqFjsS1683g5Mc93msnW21NIf4wR7kt43A+4c0fZ177T2oQU3BOVe0KkD7PuaN2wPz01Oton5rvZ6ja29EOeE3FVhhaIupJrHHwYIxRjbm59ziZcIzpkMV8yFa97yQjsZw7zRtwsfdH6P08tqTcgaW0kSSiDOzpv/Z/t97DlWfMD2vsGGCiq32AssEAtXzIOvP2LnrXoFlj5lj3fZOutpPHCMDbW4F2/2KBg0w8Z8y9fbXpufvHw4+nv291RssL1ssI1eU639zemDYPSZ1r6mWtuLdj2eyiLbuLjHvHqb13gNONyOks8YCv0nePtMH+xVsoQLQ7V6FgO8ablHwJHftfv61xlw9wQvn+JPfJesgo/vhUdn2bLfxQ/Dw6d7oRf3uBzn9KhXv+qFikpW2bDT/U7vf9PHEBVjb2AHtgFtbvREw028f/mct323EXUb5T5DYKyv0QPP63I7DcNP9Pbvnmu1JdYT9BMMekJdtcU7/93f5H7PneJ9918jRYs9z2LQDDj5V/bzKz+wnYNg0Guo3Wun33gr+OD9xzsLPVEef75991dzbf7Unofr3rWeluthpeTY6qo37ChskrLb/r7qbU6e7G373T9oNtEvFj33/BUVi31FdbF11VfO8xJSK+baUst5N3q9aWPgpRttaKm2pO2rdLUVHH+Iye0xuSOi3UbjwzvtvLnX2XCD3zMoK/Di0aPPbG9r6eowYtFJknvpU7YaY/Wr3m9ze2zRsXDO3yAuzXoVA4+0PayWBuf3/D8bo3U9BrDVQaEc6bjdbiy3/0Rre3J/uPpVe9HvqvBCL5kjIBANfUdD1igbRpj7XXu8F/0TPrjTlqt+/oR3Mfcda9dxj4kJ2jDF8JPsxTvoSPt7znQSoEsetz1aN5nsb+i+dqcNARS87Xk8buOTNcpe0MFmrwftNloAY87xPvfxiUVtSftcgRvKcsNQLif+3DZczbus5+L2/FeEiMX8P9uQ2lfPw3u32xLQde/aDk35OkBs+C1valtPtGSN/c+Lv4Lnv2XnDTsBJl3i5WxWvWzzNtljYJIzZqbwI28brhC4x6XPYBh5qhXcgdNtB6FsrRXZ+kr73fX81rzphbGgffVXzXbbAwcrFu5xKg0ViyPsb6zeZsXdZctnPhEbbPMBmSPtdrctsx2a0KrD7FEw8evWu5p6jZ229i3rqWSOsL/JPe5gPdP/fNueh4v/ZY+XCcLh34CznZsAtp4f+V5+BaxntuFDu+2+49p2FvxhqB5KboOKRdeUFtjSutDS06qttrLCTXL6k1wf3GEvNjfO2Vjj9UCXPmkvtIQ+cP1n8MO19nXjUhuO2PwJLH7I25Z74rnhFjcc4V6Auyrg9Z+09QxaGq3nAU5POiQhVrLKC0PFOM+5KFoE79wGb95qX+/+zopQdTG88VNv3Y3/te+upwP2gvzxOjjlNkjpZ29d4f89T17gjRGAtglCl+N+6DUUYBvCrz8K3//KNi5Dj7fTv3BKbLNGecu2uuhOQ/vls7YnDLZR8CeYoW1jPfZcuOx5+P5yL4ww6Eh7EdbugI0fefXs/vVS+sFpt9vPr99ij5W/8XEvbrfxdvcNbUUnfbANUcUk2vLYxpA7qLqNXmpO2+mxiXDdfLjUEYmSVTapvN0nxOve9eLhH9zhfS5ZbZcNNkP6QLutMWe33X7NdljvDv50juuYs22S3c3ZvH6LN73/ROt5tLF9i+3EuMclfTDEJsGNX8DVr3kdoFVOGXLqABh1qvUoiz61+3DPz5Uv2U7U1qV2nIs/N+SWJoO95tw8gERBal7bXrvrrfo9i/TB1utzb+5Yutrms6Bt+Cd7tK1I+vk2K5zgbcNfvOBe9+/f7nlq/vNw2AkwYmZbu9IHQVpIh2DTAvueMbTtdH+CWz2L/YTGWpu4e/2WtgNwgi023PT2r73RvO6JEJNoG+tPH/Qaeomy8dcF99pEHMDpd0DWCNurTO5rT4gz7rTz5t/j7ccNS2U7jWNoDzM63vYa/aWf4DUa/cZ6F6Xb4Jas8XIebthoxVz47//Z0d4f/9V6LnOvg9d+5PUe/YTeLDDgayhi4u3vOfP/7HfXtvRBbddJcnrUaQMhLgXO/rM9flEx1gsQ8bbrT1RC29rycbPte0Ifu83aEq+XvGWJDQsEYr3wz9DjbM9fArahi4pqeyNFEa9Bf/F6m2vpO9b+X34mX2oFbleFPU5uUjhzOKQ4YuGWJ/vFIvsw21sEO/ZCxGs4QvMWoQluP4Fob7ula73Bmm5exN+B8Fd7+cOUblhlzCx7PBKzvLBi1RbbuAZi7cv1yMad69ha7H2PiYf+4719xNkb77FlcVvPArzj7XY4XEFNHWD/Q/c8BfvfpuZZWxb81RY2vHQjfOnLUbm3TQGbW9i6BDDWKw1Et+2VD5wO0QnWo3FzHm7cv7WxX+2Ff6Z/x4ojOPk5PFv95E6xHRiJstveuQk+eQAQe41WbbEdD7D/WVSgrdefmuOdE/Hp9r1wQVv7XPxhqPSQeRFExSIczY22wuLNX3gn+ooXbeO9Y5Wt0HE9ia+etz1P97sbu9280GvoT7nNvr95q214R5zi3XXUz+izbC+zcpPt0buVQSk5Xq/Xf5JmjfIahkKnGsm90AFGnGx7fGf9GS552sa5oW0Yyn8/mZQca+vJv7H7K3jb/u7YZLjsGa+xT8yEPiG9nXCMORsufNxu8+y/wPG+h7VIlBMiwPMS+gyBb74Ol/+nbRIPvLCXi18s+o+Hy56zvVW3IXNpaQCMFYpo56ll0bFwxYtw5byOe2Zuj9JNsJ/0i/bLiNjfFZNkk8PurReOuNJ6Hi6h38HeMO6y561YgJfkrtrqeX3BoK0kgrYJbj+JGVYgm2o9sRo324YFO6J0jS/p7xz7jKH2mFzxYtu7vuZMgqtetfkht0c75Sp7Tp1yG1w8x1u+VRDFCinYTpQ/Z+HH7XC4oSv33PZ7XgOnwklOXP+tX9pwI9jj7eKvngOvMs7dnv+aSR9sw47gXQPuee2eU0WLbRg3KsYK2vn/hIufgsEzvO2E/h95+dZrGny09XJeuskbcT3oSMfOXfa/cnNwfq8lNdd2Fi95GsafZ6e5IhgaatKcxX6CMbas7/4ZNhwkUYBYl/yF62wp3/tO+GG0k3R6+WavKmXqt+w625fZCzgp2w7HH3aCnR+bDGfdHf4Zun5XeMtiL1HmD7n4wxG5+V4j6vakw+0nfaDNJ/h7Tu4oVn+y9cw/2QTvMTd5IRaAmb+yF5R7cufmd/8ZwGNn2W1OucrGdV0SsyBjuP3sb/hzJtmefyjJfSHN55lkHdZ2/shTbMPr2igBK5YuuSFi03+CvZA7IjffaxDGzYbRZ4Rfrs9gmOkTktP+19rq9qzB6yz4yRgKI332uXmL/1wLd42yhQt1ZdZLjU/v/C657vFzOwx5Uz1PFGDU6c4+HEEqXevcfoS2x37osVZ4/cc2N9822P6GMhAD+Vfb/9V/XNxj3HeMdx6uf9+G86Ji2jewof+JO3/0Wc515ywz6RKvgXdxk+jhcO+d5l4rfrFIzWkrRolZEOc8dtX1sjZ/QmsHIybehodCc3/RcV54NzreJr/BO//cKq8xs9r+zjzftTP0OM+LSMnxrlPXXje0FioI/jCUKzw9wL55ovvBxNKnbMgoJtFW9xzu3Ha7cL51faNibON92Ok2yfjQqZ5XkTbQhiCyx9hKB3AGcQnMute6z0dcYU+KjsibavMCRYtsmay7DRd/OCJvStsGFKzbXLoWplzZPuyTPsi64NXbaC0BzM23DXlKTtsLf/JlNsHYXO8NBjryu3bbR9/YnSPZHv9Jn9zX7rd0DeRf073186bYnr5EtRUeP4OPsttNH2QF0w0nhHomXREVZRv55XNtMrszpl1re6KxSV6iN/+bdtpxP4SE9K7354qFm1R9+Sb73AsIH4LykzXKyyVFx9uefvZhXjXR1/5oG/ix59rQaeVmL08waEb77fkFZHeO2+gz7T7GzbbbjYrx9Y4Htn9mSvoge24VLrDHzvW2k7KsJ1dZ5IUjZ/3VFooMnAbv/2/4/SdmWoHd7FROucetjVgMsOIZFWN7/v5zss9Qb3p3fnvqABvOzZnkhUvHnGVDki5jzmpbwuwvdAjEwGm/t4Lqeh/ghTBdQj2L+DSY9h17zHrwVu4qFi4L7oMvnrJll2Dd7EkXefPdXtsJt9gGwGXWX+Hvx9kTzD0R8qZ4YuF6BekD4XKf69wR7glatNg7Sfy9xJQQz8Lfs4hNsa7+N54Lv+2ogI27b//Sa5SSsmwoJRQR+Nof2k5Ly7XhqD0luZ9tzJrrbeOYPapjW8ORm2/DD32GdHyRRAW83+MfLLW7YgG28c7X5joAAAwwSURBVAoXLgy3z1khj7jMHG7Dad0lOSRMVb3NCga0T26H4u9M5Ey2jZDrHWSOsA3iRU/Y70ufsmIRbLadmnAPgvKLRe6U9vM7Ii4ZLvTd/HHY8Z5Yh6vaEfHyWqEce3Pb72l59ngGg7Dgb14uKD7dC00NPd4OLHRxrxV/45sywIq3a5vfrkC0/d/cfE6o5xNK6gAbQfDno1IH2PEkRZ/a99QBbRP/oefh4d+wr9Dt+gnt9AGcEfm7zIaiYSiwjcqbP7eNaFOd7Xn4G4mx59iGeMAR1vX2028snOgkrd0Baf6TzH8hdwd33a2f2/La0G3Ep1mX1x3TkOTLH4SeZOHwn9jQNv4ZaUS8Ez+0cewOI0+15ZX+8FJn9J9gG4O+47qXY+lN/HcNHXuubWDckcBd/a/+zoTbGA07wUvgt1nWdy6FjnlwyRhmj5d7nu0p/n3vq9h6VJQXqpWotufz6DOtN+ni5sRCPQuAKVfb99BQ5O54VYOPAsQbaOji5i2nXGnfk7NtSXlKTtcCFGpvUt/IPahrN1HPornR3kzMBGHqt+0fnTWqbUw+NQduWmZDU/6qH5djb7a9A7eipU3ly6j2y3dGSj/rLVRu9gav+WPIIvCtt629/kqhig1d90ABjv9J29tEhPs9kSR9sA09hQ5C6g7Zo+CHa6z73R2iY+F/PraNyt487rMn8Iv2cT+0cX833BIalgglK4wnkDPRljPHprRd1n8+hgqJSyAG/mc+IHt33A470ykZD+7b8QB5U+3YkdTctiLUbxx8b5mtPEro44V7w4nFmLPgxxu8nIGLeywT+nQtlDNusGHqxIy20w+/zHZo/EUNV8y13lxcMl3it7cHR2h3hXoWC+61PfiMYTZG3X98+MdbJmZ0Hh9M7utdWNmH2ZNQotqXnHYHd3AP2EY19MZhMQltG8xBzvLd6T2n9PeS1101QpHADXvsaWIuIX33BC4ueb/pmXWK/7/oNx6OudmrbOuqwUjp7yRbxbuDLdgGLxDSH+znFDRkDPeSsuGITdr745ac7VXrZe1mp6kz3Ph+1sj2QpCUaYXSnxdMHWBLgGOS2o45Ssywnooft/x34JFdC2VUVHuhcAmtfotJsOXh3SEuxSuQ6MFqp66IqGchIqcDfwECwD+NMX8ImR8HPAZMAcqAi4wxG0XkFOAPQCzQCPzIGPNuRIyccpWtDjr8G/uuUYkKwCVz7Mjl0JOmO8z8hT3ZW5ps6KWrk/aIK20st7vP0T7yu1bM9uUF3F2OusE2bv58kGIrjs65zzZ0IrbDcukzthzWHUfSESJw0eP2fEvL63zZvClt9xNpzrnXjsZ2Q7T7ghEn21zhwOleFWJMUtsKND+xSXDBwzZfFioOoYw+G864y1bX9SYpOTYv04MjtLtCTIQezygiAWANcApQBCwCLjHGrPAt811gojHmOhG5GJhtjLlIRA4Hio0xW0VkPPCGMabTkpD8/HyzeHE3nv2sKMrBw/oP4LFZ9lYdNxxE1/9j59py/Vl/tRWUEUREPjPGdJlMiWQYahpQYIxZb4xpBJ4GzglZ5hzALZ94DpgpImKM+dwY496YZTkQ73ghiqIoHrlTbA7jiMt725J9y6SLbchw+MzetqSVSIahcgH/E1iKgOkdLWOMaRaRSiAT8N8/+3zgc2NMQ+gORORa4FqAQYPClJcpinJwE5dsCz4ONiZd7I3Z2U+IpGcRLiAaGvPqdBkRGQfcAXwn3A6MMQ8aY/KNMfnZ2XtQXaMoiqJ0i0iKRRHgL3nJA0Lvg926jIhEA2lAufM9D3gBuMIYsy6CdiqKoihdEEmxWASMFJGhIhILXAyEPmV+HuCMXOEC4F1jjBGRdOAV4KfGmPkRtFFRFEXpBhETC2NMM3A98AawEnjGGLNcRG4TEXfo6ENApogUADcD7m1JrwdGAL8QkaXOqy+KoihKrxCx0tmeRktnFUVRdp/9oXRWURRFOUhQsVAURVG6RMVCURRF6ZKDJmchIiVAYZcLdkwWbQcD7i+oXbvH/moX7L+2qV27x/5qF+yZbYONMV0OVDtoxGJvEZHF3Uny9DRq1+6xv9oF+69tatf/b+/eQuSo8jiOf39MNMT7ekHCuppEo6DgJYiIqz64i5fgfWFVBEV9WVHUhxUjAfHBl7isSFAUZYMXvCEq5kWJBFFEjawxYxI0Jrp5UMdEBc2KEjT+fTinsWbs6prWmVMl8/tA0zX/6Z7+z79O16lL9znD6WpeML25+TSUmZk1cmdhZmaN3Fn87IG2E6jhvIbT1bygu7k5r+F0NS+Yxtx8zcLMzBr5yMLMzBq5szAzs0YzvrOQdLakTZK2SFrS/Ixpy+NPkl6W9J6kjZJuzPHbJX1SGVBxcUv5bZW0Pufw3xzbX9JLkjbn+z8UzumoSl3WSdoh6aY2aiZphaTtkjZUYn3ro2R5bnPvSlpUOK9/SXo/v/ZzeZRnJM2T9F2lbvdPV14Dcqtdd5JuzTXbJOmswnk9Vclpq6R1OV6sZgO2EWXaWUTM2BswAnwILAB2B0aBo1vKZS6wKC/vTZq//GjgduCfHajVVuDACbE7gSV5eQmwrOV1+RlwWBs1A04HFgEbmuoDLAZeIE3+dTKwpnBeZwKz8vKySl7zqo9rqWZ9111+L4wCs4H5+X07UiqvCb//N3Bb6ZoN2EYUaWcz/chiMvOEFxERYxGxNi//nzSs+x/byGUI1TnUHwYubDGXvwAfRsRv+Rb/rxYRr5In7qqoq88FwCORvAnsJ2luqbwiYlWkKQQA3iRNTFZcTc3qXAA8GRE7I+J/wBbS+7doXpIE/B14Yjpee5AB24gi7Wymdxb95glvfQMtaR5wArAmh67Ph5ErSp/qqQhglaS3leY+Bzg4IsYgNWSgzTlHLmX8G7gLNaurT5fa3dWkvc+e+ZLekfSKpNNayqnfuutKzU4DtkXE5kqseM0mbCOKtLOZ3llMZp7woiTtBTwD3BQRO4D7gMOB44Ex0iFwG/4cEYuAc4DrJJ3eUh6/oDQT4/nA0znUlZrV6US7k7QU+AF4LIfGgEMj4gTSZGSPS9qncFp1664TNQMuY/xOSfGa9dlG1D60T+xX12ymdxaTmSe8GEm7kRrBYxHxLEBEbIuIXRHxI/Ag03To3SQiPs3320lzo58EbOsd1ub77W3kRurA1kbEtpxjJ2pGfX1ab3eSrgTOBS6PfII7n+L5Mi+/TboucGTJvAasuy7UbBZwMfBUL1a6Zv22ERRqZzO9s5jMPOFF5HOh/wHei4i7KvHqOcaLgA0Tn1sgtz0l7d1bJl0g3cD4OdSvBJ4vnVs2bm+vCzXL6uqzErgif1rlZODr3mmEEiSdDdwCnB8R31biB0kaycsLgIXAR6Xyyq9bt+5WApdKmi1pfs7trZK5AX8F3o+Ij3uBkjWr20ZQqp2VuIrf5RvpEwMfkPYIlraYx6mkQ8R3gXX5thh4FFif4yuBuS3ktoD0SZRRYGOvTsABwGpgc77fv4Xc9gC+BPatxIrXjNRZjQHfk/borqmrD+n0wL25za0HTiyc1xbSuexeO7s/P/Zvef2OAmuB81qoWe26A5bmmm0CzimZV44/BPxjwmOL1WzANqJIO/NwH2Zm1mimn4YyM7NJcGdhZmaN3FmYmVkjdxZmZtbInYWZmTVyZ2E2BEm7NH6k2ykbqTiPYNrWd0LMBprVdgJmvzPfRcTxbSdhVpqPLMymQJ7jYJmkt/LtiBw/TNLqPDDeakmH5vjBSnNJjObbKflPjUh6MM9XsErSnNb+KbMKdxZmw5kz4TTUJZXf7YiIk4B7gLtz7B7SMNHHkgbsW57jy4FXIuI40twJG3N8IXBvRBwDfEX6hrBZ6/wNbrMhSPomIvbqE98KnBERH+XB3j6LiAMkfUEasuL7HB+LiAMlfQ4cEhE7K39jHvBSRCzMP98C7BYRd0z/f2Y2mI8szKZO1CzXPaafnZXlXfi6onWEOwuzqXNJ5f6NvPw6aTRjgMuB1/LyauBaAEkjLcwbYTYU77WYDWeOpHWVn1+MiN7HZ2dLWkPaCbssx24AVki6GfgcuCrHbwQekHQN6QjiWtJIp2ad5GsWZlMgX7M4MSK+aDsXs+ng01BmZtbIRxZmZtbIRxZmZtbInYWZmTVyZ2FmZo3cWZiZWSN3FmZm1ugneccUlIoP4lAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Loss')\n",
    "plt.plot(history['acc'], linewidth=2, label='Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model Loss/Accuracy')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'current_model' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0af44f232b89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mgame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAIGame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomAIPlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNNPlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNNTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmoves\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwinner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwinner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\proj\\checkers\\checkers\\ai\\analyzer\\nn_trainer.py\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcurrent_model\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mcurrent_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/nn_model.pickle.dat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcurrent_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'current_model' referenced before assignment"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(0,1000):\n",
    "    game = AIGame(RandomAIPlayer(), NNPlayer(NNTrainer().get_model()))\n",
    "    moves, winner = game.play()\n",
    "    results.add(winner)\n",
    "    print(f'Winner = {winner} ({len(moves)} moves)')\n",
    "print(f'AI wins: {np.sum([w == 2 for w in results])}, random player wins: {np.sum([w == 1 for w in results])}, draws: {np.sum([w == None for w in results])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
